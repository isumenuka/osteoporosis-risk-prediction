{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWFh-8QnMkhG"
   },
   "source": [
    "# \ud83c\udfe5 OSTEOPOROSIS RISK PREDICTION - COMPLETE MASTER PIPELINE\n",
    "\n",
    "## \ud83c\udfaf All-in-One Comprehensive Machine Learning Workflow\n",
    "\n",
    "**Project:** Osteoporosis Risk Prediction  \n",
    "**Group:** DSGP Group 40  \n",
    "**Date:** January 2026  \n",
    "**Status:** \u2705 Production Ready  \n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udccb **Notebook Structure**\n",
    "\n",
    "This master notebook combines all 10 comprehensive sections into one unified workflow:\n",
    "\n",
    "1. \u2705 **Environment Setup** - Libraries & Configuration\n",
    "2. \u2705 **Data Preparation** - Loading & Initial Exploration\n",
    "3. \u2705 **Data Preprocessing** - Cleaning & Feature Engineering\n",
    "4. \u2705 **Model Training** - 12 ML Algorithms\n",
    "5. \u2705 **Gender-Specific Models** - Separate Male/Female XGBoost\n",
    "6. \u2705 **Hyperparameter Tuning** - Top 4 Models Optimization\n",
    "7. \u2705 **Confusion Matrices** - All Models with Comparison\n",
    "8. \u2705 **SHAP Analysis** - Advanced Explainability (5 visualization types)\n",
    "9. \u2705 **Loss Curve Analysis** - Top 4 Algorithms (8 visualization types)\n",
    "10. \u2705 **Complete Leaderboard** - All Models Ranked\n",
    "\n",
    "**Total Run Time:** ~85-110 minutes (GPU: ~45-60 minutes)  \n",
    "**Output Files:** 58+ visualizations + 9 CSV files  \n",
    "**Model Comparison:** 14 models evaluated with multiple metrics\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umdSZthyXVOh"
   },
   "source": [
    "## \ud83d\udcda TABLE OF CONTENTS\n",
    "\n",
    "| Section | Subsections | Est. Time |\n",
    "|---------|-------------|-----------|\n",
    "| **PART 1** | Environment & Libraries | 2 min |\n",
    "| **PART 2** | Data Loading & Exploration | 5 min |\n",
    "| **PART 3** | Data Cleaning & Features | 10 min |\n",
    "| **PART 4** | Model Training (12 algorithms) | 20-25 min |\n",
    "| **PART 5** | Gender-Specific XGBoost Models | 15-20 min |\n",
    "| **PART 6** | Hyperparameter Tuning (Top 4) | 15-20 min |\n",
    "| **PART 7** | Confusion Matrices (All Models) | 5 min |\n",
    "| **PART 8** | SHAP Interpretability (5 types) | 5 min |\n",
    "| **PART 9** | Loss Curves (8 visualizations) | 5-10 min |\n",
    "| **PART 10** | Complete Leaderboard & Results | 10 min |\n",
    "| **Total** | Complete ML Pipeline | 85-110 min |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPZKjBUsMkhN"
   },
   "source": [
    "# \ud83d\udd27 PART 1: ENVIRONMENT SETUP & CONFIGURATION\n",
    "\n",
    "*Duration: ~2 minutes*\n",
    "\n",
    "**Objective:** Import all required libraries and set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BtEn2RQgJBV"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT SECTION 1.1: CORE LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "print('\u2705 Core libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_j5ECZWgJBW"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT SECTION 1.2: SCIKIT-LEARN & MODELS\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, confusion_matrix,\n",
    "                            classification_report, roc_curve, auc, f1_score, precision_score)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                             AdaBoostClassifier, BaggingClassifier, StackingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print('\u2705 Scikit-learn, XGBoost, and TensorFlow imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOHvAN1JgJBX"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT SECTION 1.3: INTERPRETABILITY & UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "import shap\n",
    "import pickle\n",
    "import os\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "print('\u2705 SHAP and utilities imported!')\n",
    "print('\u2705 Output directories created!')\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83c\udfaf ALL LIBRARIES IMPORTED - READY TO PROCEED')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RrUqDJCgJBY"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION: Global Settings\n",
    "# ============================================================================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.2\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "N_ESTIMATORS = 200\n",
    "MAX_DEPTH = 5\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "NN_EPOCHS = 100\n",
    "NN_BATCH_SIZE = 32\n",
    "NN_LEARNING_RATE = 0.001\n",
    "\n",
    "DPI = 300\n",
    "FIG_SIZE = (14, 8)\n",
    "\n",
    "print('\u2705 Configuration set:')\n",
    "print(f'   \u2022 Random Seed: {RANDOM_SEED}')\n",
    "print(f'   \u2022 Test/Train Split: {TEST_SIZE}')\n",
    "print(f'   \u2022 Cross-Validation Folds: {N_FOLDS}')\n",
    "print(f'   \u2022 Figure Resolution: {DPI} DPI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRQQoF0XgJBY"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcca PART 2: DATA LOADING & EXPLORATION\n",
    "\n",
    "*Duration: ~5 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO24R5A9gJBZ"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2.1: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "csv_path = 'data/osteoporosis_data.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f'\u2705 Dataset loaded successfully!')\n",
    "    print(f'   Shape: {df.shape} (rows, columns)')\n",
    "except FileNotFoundError:\n",
    "    print(f'\u274c File not found: {csv_path}')\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS_UCXahgJBa"
   },
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print('\\n' + '='*80)\n",
    "    print('DATA OVERVIEW')\n",
    "    print('='*80)\n",
    "    print(f'\\nShape: {df.shape}')\n",
    "    print(f'Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
    "    print(f'\\nColumns: {df.columns.tolist()}')\n",
    "    print(f'\\nMissing Values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2v2QeXDgJBa"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83e\uddf9 PART 3: DATA PREPROCESSING & FEATURE ENGINEERING\n",
    "\n",
    "*Duration: ~10 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5Ao8kRBgJBa"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3.1: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "if df is not None:\n",
    "    # Create working copy\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Drop ID column (not useful for prediction)\n",
    "    df_processed = df_processed.drop('Id', axis=1)\n",
    "\n",
    "    # Handle missing values\n",
    "    # Fill categorical with 'Unknown'\n",
    "    categorical_cols = df_processed.select_dtypes(include='object').columns\n",
    "    for col in categorical_cols:\n",
    "        df_processed[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    le_dict = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col])\n",
    "        le_dict[col] = le\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df_processed.drop('Osteoporosis', axis=1)\n",
    "    y = df_processed['Osteoporosis']\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "\n",
    "    print('\u2705 Data preprocessing complete!')\n",
    "    print(f'   Training set: {X_train.shape}')\n",
    "    print(f'   Test set: {X_test.shape}')\n",
    "    print(f'   Features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a_O_6JVgJBb"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83e\udd16 PART 4: MODEL TRAINING (12 ALGORITHMS)\n",
    "\n",
    "*Duration: ~20-25 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2ZMTbN_gJBb"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 4.1: TRAIN ALL 12 MODELS (BASELINE)\n",
    "# ============================================================================\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=MAX_DEPTH, random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH, random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, random_state=RANDOM_STATE),\n",
    "    'XGBoost': XGBClassifier(n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, random_state=RANDOM_STATE, verbosity=0),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE),\n",
    "    'Bagging': BaggingClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE),\n",
    "    'Neural Network': keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    'Stacking': StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "            ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression()\n",
    "    ),\n",
    "    'XGBoost Tuned': XGBClassifier(n_estimators=200, learning_rate=0.03, max_depth=6, random_state=RANDOM_STATE, verbosity=0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "print('\ud83e\udd16 Training 12 baseline models... This may take 5-10 minutes')\n",
    "print('='*80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\nTraining: {name}...')\n",
    "\n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=NN_EPOCHS, batch_size=NN_BATCH_SIZE, verbose=0)\n",
    "        y_pred = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
    "        y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'roc_auc': roc,\n",
    "        'f1_score': f1,\n",
    "        'precision': prec\n",
    "    }\n",
    "    trained_models[name] = model\n",
    "\n",
    "    print(f'  \u2705 Accuracy: {acc:.4f} | ROC-AUC: {roc:.4f} | F1: {f1:.4f}')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2705 All 12 baseline models trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udc68\u200d\u2695\ufe0f\ud83d\udc69\u200d\u2695\ufe0f PART 5: GENDER-SPECIFIC XGBOOST MODELS\n",
    "\n",
    "*Duration: ~15-20 minutes*\n",
    "\n",
    "**Objective:** Train separate XGBoost models for male and female patients to improve prediction accuracy by accounting for biological differences in osteoporosis risk factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.1: GENDER DATA SPLITTING\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udc68\u200d\u2695\ufe0f\ud83d\udc69\u200d\u2695\ufe0f GENDER-SPECIFIC MODEL TRAINING')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Split by gender (0=Male, 1=Female)\\n",
    "df_male = df_processed[df_processed['Gender'] == 0].copy()\\n",
    "df_female = df_processed[df_processed['Gender'] == 1].copy()\\n",
    "\\n",
    "# Separate features and target for males\\n",
    "X_male = df_male.drop(['Osteoporosis', 'Gender'], axis=1)\\n",
    "y_male = df_male['Osteoporosis']\\n",
    "\\n",
    "# Separate features and target for females\\n",
    "X_female = df_female.drop(['Osteoporosis', 'Gender'], axis=1)\\n",
    "y_female = df_female['Osteoporosis']\\n",
    "\\n",
    "print('\\\\n\ud83d\udcca Dataset Statistics:')\\n",
    "print(f'   \ud83d\udc68 Male samples: {len(df_male)} ({len(df_male)/len(df_processed)*100:.1f}%)')\\n",
    "print(f'   \ud83d\udc69 Female samples: {len(df_female)} ({len(df_female)/len(df_processed)*100:.1f}%)')\\n",
    "print(f'\\\\n   \ud83d\udc68 Male osteoporosis rate: {y_male.mean()*100:.2f}%')\\n",
    "print(f'   \ud83d\udc69 Female osteoporosis rate: {y_female.mean()*100:.2f}%')\\n",
    "print(f'\\\\n   Features (excl. Gender): {X_male.shape[1]}')\\n",
    "\\n",
    "print('\\\\n\u2705 Gender-based data splitting complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.2: SEPARATE FEATURE SCALING\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udccf GENDER-SPECIFIC FEATURE SCALING')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Create separate scalers\\n",
    "scaler_male = StandardScaler()\\n",
    "scaler_female = StandardScaler()\\n",
    "\\n",
    "# Scale male data\\n",
    "X_male_scaled = scaler_male.fit_transform(X_male)\\n",
    "X_male_scaled = pd.DataFrame(X_male_scaled, columns=X_male.columns)\\n",
    "\\n",
    "# Scale female data\\n",
    "X_female_scaled = scaler_female.fit_transform(X_female)\\n",
    "X_female_scaled = pd.DataFrame(X_female_scaled, columns=X_female.columns)\\n",
    "\\n",
    "print('\\\\n\u2705 Gender-specific scaling complete!')\\n",
    "print(f'   \ud83d\udc68 Male features scaled: {X_male_scaled.shape}')\\n",
    "print(f'   \ud83d\udc69 Female features scaled: {X_female_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.3: GENDER-SPECIFIC TRAIN-TEST SPLIT\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udd00 GENDER-SPECIFIC TRAIN-TEST SPLIT')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Split male data\\n",
    "X_train_male, X_test_male, y_train_male, y_test_male = train_test_split(\\n",
    "    X_male_scaled, y_male, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_male\\n",
    ")\\n",
    "\\n",
    "# Split female data\\n",
    "X_train_female, X_test_female, y_train_female, y_test_female = train_test_split(\\n",
    "    X_female_scaled, y_female, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_female\\n",
    ")\\n",
    "\\n",
    "print('\\\\n\ud83d\udc68 Male Dataset:')\\n",
    "print(f'   Training: {X_train_male.shape}')\\n",
    "print(f'   Testing: {X_test_male.shape}')\\n",
    "\\n",
    "print('\\\\n\ud83d\udc69 Female Dataset:')\\n",
    "print(f'   Training: {X_train_female.shape}')\\n",
    "print(f'   Testing: {X_test_female.shape}')\\n",
    "\\n",
    "print('\\\\n\u2705 Train-test split complete for both genders!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.4: TRAIN MALE XGBOOST MODEL\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udc68 TRAINING MALE-SPECIFIC XGBOOST MODEL')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Male model parameters\\n",
    "male_model = XGBClassifier(\\n",
    "    n_estimators=200,\\n",
    "    max_depth=5,\\n",
    "    learning_rate=0.05,\\n",
    "    subsample=0.8,\\n",
    "    colsample_bytree=0.8,\\n",
    "    min_child_weight=3,\\n",
    "    gamma=0.1,\\n",
    "    random_state=RANDOM_STATE,\\n",
    "    verbosity=0,\\n",
    "    eval_metric='logloss'\\n",
    ")\\n",
    "\\n",
    "# Train with eval_set\\n",
    "eval_set_male = [(X_train_male, y_train_male), (X_test_male, y_test_male)]\\n",
    "male_model.fit(X_train_male, y_train_male, eval_set=eval_set_male, verbose=False)\\n",
    "\\n",
    "# Generate predictions\\n",
    "y_pred_male = male_model.predict(X_test_male)\\n",
    "y_pred_proba_male = male_model.predict_proba(X_test_male)[:, 1]\\n",
    "\\n",
    "print('\\\\n\u2705 Male model training complete!')\\n",
    "print('\\\\n\ud83d\udcca Target Performance:')\\n",
    "print('   AUC: 0.845-0.880')\\n",
    "print('   Accuracy: 86-89%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.5: TRAIN FEMALE XGBOOST MODEL\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udc69 TRAINING FEMALE-SPECIFIC XGBOOST MODEL')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Female model parameters\\n",
    "female_model = XGBClassifier(\\n",
    "    n_estimators=200,\\n",
    "    max_depth=6,\\n",
    "    learning_rate=0.05,\\n",
    "    subsample=0.8,\\n",
    "    colsample_bytree=0.8,\\n",
    "    min_child_weight=2,\\n",
    "    gamma=0.1,\\n",
    "    random_state=RANDOM_STATE,\\n",
    "    verbosity=0,\\n",
    "    eval_metric='logloss'\\n",
    ")\\n",
    "\\n",
    "# Train with eval_set\\n",
    "eval_set_female = [(X_train_female, y_train_female), (X_test_female, y_test_female)]\\n",
    "female_model.fit(X_train_female, y_train_female, eval_set=eval_set_female, verbose=False)\\n",
    "\\n",
    "# Generate predictions\\n",
    "y_pred_female = female_model.predict(X_test_female)\\n",
    "y_pred_proba_female = female_model.predict_proba(X_test_female)[:, 1]\\n",
    "\\n",
    "print('\\\\n\u2705 Female model training complete!')\\n",
    "print('\\\\n\ud83d\udcca Target Performance:')\\n",
    "print('   AUC: 0.859-0.891')\\n",
    "print('   Accuracy: 88-91%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.6: PERFORMANCE METRICS\\n",
    "# ============================================================================\\n",
    "\\n",
    "from sklearn.metrics import recall_score\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udcca GENDER-SPECIFIC MODEL PERFORMANCE')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Calculate metrics for male model\\n",
    "male_metrics = {\\n",
    "    'accuracy': accuracy_score(y_test_male, y_pred_male),\\n",
    "    'precision': precision_score(y_test_male, y_pred_male),\\n",
    "    'recall': recall_score(y_test_male, y_pred_male),\\n",
    "    'f1_score': f1_score(y_test_male, y_pred_male),\\n",
    "    'roc_auc': roc_auc_score(y_test_male, y_pred_proba_male)\\n",
    "}\\n",
    "\\n",
    "# Calculate metrics for female model\\n",
    "female_metrics = {\\n",
    "    'accuracy': accuracy_score(y_test_female, y_pred_female),\\n",
    "    'precision': precision_score(y_test_female, y_pred_female),\\n",
    "    'recall': recall_score(y_test_female, y_pred_female),\\n",
    "    'f1_score': f1_score(y_test_female, y_pred_female),\\n",
    "    'roc_auc': roc_auc_score(y_test_female, y_pred_proba_female)\\n",
    "}\\n",
    "\\n",
    "# Print comprehensive metrics\\n",
    "print('\\\\n\ud83d\udc68 MALE MODEL PERFORMANCE:')\\n",
    "print(f'   \u2022 Accuracy:  {male_metrics[\\\"accuracy\\\"]:.4f}')\\n",
    "print(f'   \u2022 Precision: {male_metrics[\\\"precision\\\"]:.4f}')\\n",
    "print(f'   \u2022 Recall:    {male_metrics[\\\"recall\\\"]:.4f}')\\n",
    "print(f'   \u2022 F1-Score:  {male_metrics[\\\"f1_score\\\"]:.4f}')\\n",
    "print(f'   \u2022 ROC-AUC:   {male_metrics[\\\"roc_auc\\\"]:.4f}')\\n",
    "\\n",
    "print('\\\\n\ud83d\udc69 FEMALE MODEL PERFORMANCE:')\\n",
    "print(f'   \u2022 Accuracy:  {female_metrics[\\\"accuracy\\\"]:.4f}')\\n",
    "print(f'   \u2022 Precision: {female_metrics[\\\"precision\\\"]:.4f}')\\n",
    "print(f'   \u2022 Recall:    {female_metrics[\\\"recall\\\"]:.4f}')\\n",
    "print(f'   \u2022 F1-Score:  {female_metrics[\\\"f1_score\\\"]:.4f}')\\n",
    "print(f'   \u2022 ROC-AUC:   {female_metrics[\\\"roc_auc\\\"]:.4f}')\\n",
    "\\n",
    "# Create comparison table\\n",
    "comparison_df = pd.DataFrame({\\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\\n",
    "    '\ud83d\udc68 Male': [\\n",
    "        f\\\"{male_metrics['accuracy']:.4f}\\\",\\n",
    "        f\\\"{male_metrics['precision']:.4f}\\\",\\n",
    "        f\\\"{male_metrics['recall']:.4f}\\\",\\n",
    "        f\\\"{male_metrics['f1_score']:.4f}\\\",\\n",
    "        f\\\"{male_metrics['roc_auc']:.4f}\\\"\\n",
    "    ],\\n",
    "    '\ud83d\udc69 Female': [\\n",
    "        f\\\"{female_metrics['accuracy']:.4f}\\\",\\n",
    "        f\\\"{female_metrics['precision']:.4f}\\\",\\n",
    "        f\\\"{female_metrics['recall']:.4f}\\\",\\n",
    "        f\\\"{female_metrics['f1_score']:.4f}\\\",\\n",
    "        f\\\"{female_metrics['roc_auc']:.4f}\\\"\\n",
    "    ]\\n",
    "})\\n",
    "\\n",
    "print('\\\\n\ud83d\udcca PERFORMANCE COMPARISON:')\\n",
    "print(comparison_df.to_string(index=False))\\n",
    "\\n",
    "# Classification reports\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udc68 MALE MODEL - CLASSIFICATION REPORT')\\n",
    "print('='*80)\\n",
    "print(classification_report(y_test_male, y_pred_male))\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udc69 FEMALE MODEL - CLASSIFICATION REPORT')\\n",
    "print('='*80)\\n",
    "print(classification_report(y_test_female, y_pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.7: CONFUSION MATRICES VISUALIZATION\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udcca CONFUSION MATRICES - GENDER-SPECIFIC MODELS')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Create confusion matrices\\n",
    "cm_male = confusion_matrix(y_test_male, y_pred_male)\\n",
    "cm_female = confusion_matrix(y_test_female, y_pred_female)\\n",
    "\\n",
    "# Create side-by-side visualization\\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\\n",
    "\\n",
    "# Male confusion matrix\\n",
    "sns.heatmap(cm_male, annot=True, fmt='d', cmap='Blues', ax=axes[0],\\n",
    "            xticklabels=['No Osteoporosis', 'Osteoporosis'],\\n",
    "            yticklabels=['No Osteoporosis', 'Osteoporosis'])\\n",
    "axes[0].set_title(f'\ud83d\udc68 Male Model\\\\nAccuracy: {male_metrics[\\\"accuracy\\\"]:.4f} | AUC: {male_metrics[\\\"roc_auc\\\"]:.4f}',\\n",
    "                  fontsize=12, fontweight='bold', pad=15)\\n",
    "axes[0].set_ylabel('True Label', fontsize=11, fontweight='bold')\\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=11, fontweight='bold')\\n",
    "\\n",
    "# Female confusion matrix\\n",
    "sns.heatmap(cm_female, annot=True, fmt='d', cmap='Reds', ax=axes[1],\\n",
    "            xticklabels=['No Osteoporosis', 'Osteoporosis'],\\n",
    "            yticklabels=['No Osteoporosis', 'Osteoporosis'])\\n",
    "axes[1].set_title(f'\ud83d\udc69 Female Model\\\\nAccuracy: {female_metrics[\\\"accuracy\\\"]:.4f} | AUC: {female_metrics[\\\"roc_auc\\\"]:.4f}',\\n",
    "                  fontsize=12, fontweight='bold', pad=15)\\n",
    "axes[1].set_ylabel('True Label', fontsize=11, fontweight='bold')\\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=11, fontweight='bold')\\n",
    "\\n",
    "plt.suptitle('Gender-Specific XGBoost Models - Confusion Matrices', fontsize=14, fontweight='bold', y=1.02)\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('figures/gender_specific_confusion_matrices.png', dpi=DPI, bbox_inches='tight')\\n",
    "plt.show()\\n",
    "\\n",
    "print('\\\\n\u2705 Confusion matrices saved to: figures/gender_specific_confusion_matrices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.8: ROC CURVES COMPARISON\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udcc8 ROC CURVES - GENDER-SPECIFIC MODELS')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Calculate ROC curves\\n",
    "fpr_male, tpr_male, _ = roc_curve(y_test_male, y_pred_proba_male)\\n",
    "fpr_female, tpr_female, _ = roc_curve(y_test_female, y_pred_proba_female)\\n",
    "\\n",
    "# Create visualization\\n",
    "plt.figure(figsize=(10, 8))\\n",
    "\\n",
    "# Plot male ROC curve\\n",
    "plt.plot(fpr_male, tpr_male, color='#3498db', linewidth=2.5,\\n",
    "         label=f'\ud83d\udc68 Male Model (AUC = {male_metrics[\\\"roc_auc\\\"]:.4f})')\\n",
    "\\n",
    "# Plot female ROC curve\\n",
    "plt.plot(fpr_female, tpr_female, color='#e74c3c', linewidth=2.5,\\n",
    "         label=f'\ud83d\udc69 Female Model (AUC = {female_metrics[\\\"roc_auc\\\"]:.4f})')\\n",
    "\\n",
    "# Plot random classifier baseline\\n",
    "plt.plot([0, 1], [0, 1], color='black', linewidth=1.5, linestyle='--',\\n",
    "         label='Random Classifier (AUC = 0.5000)')\\n",
    "\\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\\n",
    "plt.title('ROC Curves - Gender-Specific XGBoost Models', fontsize=14, fontweight='bold', pad=20)\\n",
    "plt.legend(loc='lower right', fontsize=11, frameon=True, shadow=True)\\n",
    "plt.grid(alpha=0.3, linestyle='--')\\n",
    "plt.xlim([0.0, 1.0])\\n",
    "plt.ylim([0.0, 1.05])\\n",
    "\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('figures/gender_specific_roc_curves.png', dpi=DPI, bbox_inches='tight')\\n",
    "plt.show()\\n",
    "\\n",
    "print('\\\\n\u2705 ROC curves saved to: figures/gender_specific_roc_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.9: 5-FOLD CROSS-VALIDATION\\n",
    "# ============================================================================\\n",
    "\\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udd04 5-FOLD CROSS-VALIDATION')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Define cross-validation\\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\\n",
    "\\n",
    "# Male model cross-validation\\n",
    "print('\\\\n\ud83d\udc68 Male Model Cross-Validation:')\\n",
    "cv_male_scores = cross_validate(\\n",
    "    male_model, X_male_scaled, y_male,\\n",
    "    cv=cv_strategy,\\n",
    "    scoring=['accuracy', 'roc_auc'],\\n",
    "    n_jobs=-1\\n",
    ")\\n",
    "\\n",
    "print(f'   Accuracy scores: {cv_male_scores[\\\"test_accuracy\\\"]}')\\n",
    "print(f'   Mean Accuracy: {cv_male_scores[\\\"test_accuracy\\\"].mean():.4f} \u00b1 {cv_male_scores[\\\"test_accuracy\\\"].std():.4f}')\\n",
    "print(f'   ROC-AUC scores: {cv_male_scores[\\\"test_roc_auc\\\"]}')\\n",
    "print(f'   Mean ROC-AUC: {cv_male_scores[\\\"test_roc_auc\\\"].mean():.4f} \u00b1 {cv_male_scores[\\\"test_roc_auc\\\"].std():.4f}')\\n",
    "\\n",
    "# Female model cross-validation\\n",
    "print('\\\\n\ud83d\udc69 Female Model Cross-Validation:')\\n",
    "cv_female_scores = cross_validate(\\n",
    "    female_model, X_female_scaled, y_female,\\n",
    "    cv=cv_strategy,\\n",
    "    scoring=['accuracy', 'roc_auc'],\\n",
    "    n_jobs=-1\\n",
    ")\\n",
    "\\n",
    "print(f'   Accuracy scores: {cv_female_scores[\\\"test_accuracy\\\"]}')\\n",
    "print(f'   Mean Accuracy: {cv_female_scores[\\\"test_accuracy\\\"].mean():.4f} \u00b1 {cv_female_scores[\\\"test_accuracy\\\"].std():.4f}')\\n",
    "print(f'   ROC-AUC scores: {cv_female_scores[\\\"test_roc_auc\\\"]}')\\n",
    "print(f'   Mean ROC-AUC: {cv_female_scores[\\\"test_roc_auc\\\"].mean():.4f} \u00b1 {cv_female_scores[\\\"test_roc_auc\\\"].std():.4f}')\\n",
    "\\n",
    "print('\\\\n\u2705 Cross-validation complete for both models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.10: SHAP ANALYSIS\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udd0d SHAP ANALYSIS - FEATURE IMPORTANCE')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Male model SHAP analysis\\n",
    "print('\\\\n\ud83d\udc68 Analyzing male model...')\\n",
    "explainer_male = shap.TreeExplainer(male_model)\\n",
    "shap_values_male = explainer_male.shap_values(X_test_male)\\n",
    "\\n",
    "plt.figure(figsize=(10, 6))\\n",
    "shap.summary_plot(shap_values_male, X_test_male, plot_type='bar', show=False)\\n",
    "plt.title('\ud83d\udc68 Male Model - SHAP Feature Importance', fontsize=14, fontweight='bold', pad=15)\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('figures/shap_male_model.png', dpi=DPI, bbox_inches='tight')\\n",
    "plt.show()\\n",
    "print('\u2705 Male SHAP plot saved to: figures/shap_male_model.png')\\n",
    "\\n",
    "# Female model SHAP analysis\\n",
    "print('\\\\n\ud83d\udc69 Analyzing female model...')\\n",
    "explainer_female = shap.TreeExplainer(female_model)\\n",
    "shap_values_female = explainer_female.shap_values(X_test_female)\\n",
    "\\n",
    "plt.figure(figsize=(10, 6))\\n",
    "shap.summary_plot(shap_values_female, X_test_female, plot_type='bar', show=False)\\n",
    "plt.title('\ud83d\udc69 Female Model - SHAP Feature Importance', fontsize=14, fontweight='bold', pad=15)\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('figures/shap_female_model.png', dpi=DPI, bbox_inches='tight')\\n",
    "plt.show()\\n",
    "print('\u2705 Female SHAP plot saved to: figures/shap_female_model.png')\\n",
    "\\n",
    "print('\\\\n\u2705 SHAP analysis complete for both models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.11: SAVE MODELS AND SCALERS\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udcbe SAVING GENDER-SPECIFIC MODELS')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Save male model and scaler\\n",
    "with open('models/osteoporosis_male_model.pkl', 'wb') as f:\\n",
    "    pickle.dump(male_model, f)\\n",
    "print('\u2705 Male model saved: models/osteoporosis_male_model.pkl')\\n",
    "\\n",
    "with open('models/scaler_male.pkl', 'wb') as f:\\n",
    "    pickle.dump(scaler_male, f)\\n",
    "print('\u2705 Male scaler saved: models/scaler_male.pkl')\\n",
    "\\n",
    "# Save female model and scaler\\n",
    "with open('models/osteoporosis_female_model.pkl', 'wb') as f:\\n",
    "    pickle.dump(female_model, f)\\n",
    "print('\u2705 Female model saved: models/osteoporosis_female_model.pkl')\\n",
    "\\n",
    "with open('models/scaler_female.pkl', 'wb') as f:\\n",
    "    pickle.dump(scaler_female, f)\\n",
    "print('\u2705 Female scaler saved: models/scaler_female.pkl')\\n",
    "\\n",
    "print('\\\\n\u2705 All gender-specific models and scalers saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n",
    "# SECTION 5.12: UPDATE RESULTS DICTIONARY\\n",
    "# ============================================================================\\n",
    "\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\ud83d\udcca UPDATING RESULTS DICTIONARIES')\\n",
    "print('='*80)\\n",
    "\\n",
    "# Add to results dictionary\\n",
    "results['Male XGBoost'] = male_metrics\\n",
    "results['Female XGBoost'] = female_metrics\\n",
    "\\n",
    "# Add to trained models\\n",
    "trained_models['Male XGBoost'] = male_model\\n",
    "trained_models['Female XGBoost'] = female_model\\n",
    "\\n",
    "# Create gender-specific summary\\n",
    "gender_summary = pd.DataFrame({\\n",
    "    'Model': ['Male XGBoost', 'Female XGBoost'],\\n",
    "    'Accuracy': [male_metrics['accuracy'], female_metrics['accuracy']],\\n",
    "    'Precision': [male_metrics['precision'], female_metrics['precision']],\\n",
    "    'Recall': [male_metrics['recall'], female_metrics['recall']],\\n",
    "    'F1-Score': [male_metrics['f1_score'], female_metrics['f1_score']],\\n",
    "    'ROC-AUC': [male_metrics['roc_auc'], female_metrics['roc_auc']],\\n",
    "    'Target AUC Range': ['0.845-0.880', '0.859-0.891'],\\n",
    "    'Target Accuracy Range': ['86-89%', '88-91%']\\n",
    "})\\n",
    "\\n",
    "# Save summary\\n",
    "gender_summary.to_csv('outputs/gender_specific_performance_summary.csv', index=False)\\n",
    "\\n",
    "print('\\\\n\ud83d\udcca Gender-Specific Performance Summary:')\\n",
    "print(gender_summary.to_string(index=False))\\n",
    "\\n",
    "print('\\\\n\u2705 Summary saved to: outputs/gender_specific_performance_summary.csv')\\n",
    "print('\\\\n' + '='*80)\\n",
    "print('\u2705 GENDER-SPECIFIC MODEL TRAINING COMPLETE!')\\n",
    "print('='*80)\\n",
    "print(f'\\\\nTotal models in results dictionary: {len(results)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mfwmp4E-vg90"
   },
   "source": [
    "---\n",
    "\n",
    "# \u2699\ufe0f PART 6: HYPERPARAMETER TUNING (TOP 4 MODELS)\n",
    "\n",
    "*Duration: ~15-20 minutes*\n",
    "\n",
    "**Objective:** Optimize hyperparameters for top 4 performing models:\n",
    "- XGBoost (GridSearchCV)\n",
    "- Gradient Boosting (GridSearchCV)\n",
    "- Random Forest (RandomizedSearchCV)\n",
    "- Bagging (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlGG8onJvg91"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6.1: HYPERPARAMETER TUNING - XGBOOST (GridSearchCV)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2699\ufe0f HYPERPARAMETER TUNING - XGBOOST')\n",
    "print('='*80)\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "print('\\n\ud83d\udd0d Searching best parameters for XGBoost...')\n",
    "print(f'   Parameter grid size: {len(xgb_param_grid[\"n_estimators\"]) * len(xgb_param_grid[\"max_depth\"]) * len(xgb_param_grid[\"learning_rate\"]) * len(xgb_param_grid[\"subsample\"]) * len(xgb_param_grid[\"colsample_bytree\"]) * len(xgb_param_grid[\"gamma\"])} combinations')\n",
    "print(f'   Cross-validation folds: {N_FOLDS}')\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBClassifier(random_state=RANDOM_STATE, verbosity=0),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=N_FOLDS,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n\u2705 Best XGBoost Parameters:')\n",
    "for param, value in xgb_grid.best_params_.items():\n",
    "    print(f'   \u2022 {param}: {value}')\n",
    "print(f'\\n\ud83d\udcca Best CV Score (ROC-AUC): {xgb_grid.best_score_:.4f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_xgb),\n",
    "    'f1_score': f1_score(y_test, y_pred_xgb),\n",
    "    'precision': precision_score(y_test, y_pred_xgb)\n",
    "}\n",
    "\n",
    "print(f'\\n\ud83d\udcc8 Test Set Performance:')\n",
    "print(f'   \u2022 Accuracy: {xgb_results[\"accuracy\"]:.4f}')\n",
    "print(f'   \u2022 ROC-AUC: {xgb_results[\"roc_auc\"]:.4f}')\n",
    "print(f'   \u2022 F1-Score: {xgb_results[\"f1_score\"]:.4f}')\n",
    "print(f'   \u2022 Precision: {xgb_results[\"precision\"]:.4f}')\n",
    "\n",
    "# Update results and models\n",
    "results['XGBoost Optimized'] = xgb_results\n",
    "trained_models['XGBoost Optimized'] = xgb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0je0t0Zcvg92"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6.2: HYPERPARAMETER TUNING - GRADIENT BOOSTING (GridSearchCV)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2699\ufe0f HYPERPARAMETER TUNING - GRADIENT BOOSTING')\n",
    "print('='*80)\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print('\\n\ud83d\udd0d Searching best parameters for Gradient Boosting...')\n",
    "print(f'   Parameter grid size: {len(gb_param_grid[\"n_estimators\"]) * len(gb_param_grid[\"max_depth\"]) * len(gb_param_grid[\"learning_rate\"]) * len(gb_param_grid[\"subsample\"]) * len(gb_param_grid[\"min_samples_split\"]) * len(gb_param_grid[\"min_samples_leaf\"])} combinations')\n",
    "print(f'   Cross-validation folds: {N_FOLDS}')\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=N_FOLDS,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n\u2705 Best Gradient Boosting Parameters:')\n",
    "for param, value in gb_grid.best_params_.items():\n",
    "    print(f'   \u2022 {param}: {value}')\n",
    "print(f'\\n\ud83d\udcca Best CV Score (ROC-AUC): {gb_grid.best_score_:.4f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred_gb = gb_best.predict(X_test)\n",
    "y_pred_proba_gb = gb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "gb_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_gb),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_gb),\n",
    "    'f1_score': f1_score(y_test, y_pred_gb),\n",
    "    'precision': precision_score(y_test, y_pred_gb)\n",
    "}\n",
    "\n",
    "print(f'\\n\ud83d\udcc8 Test Set Performance:')\n",
    "print(f'   \u2022 Accuracy: {gb_results[\"accuracy\"]:.4f}')\n",
    "print(f'   \u2022 ROC-AUC: {gb_results[\"roc_auc\"]:.4f}')\n",
    "print(f'   \u2022 F1-Score: {gb_results[\"f1_score\"]:.4f}')\n",
    "print(f'   \u2022 Precision: {gb_results[\"precision\"]:.4f}')\n",
    "\n",
    "# Update results and models\n",
    "results['Gradient Boosting Optimized'] = gb_results\n",
    "trained_models['Gradient Boosting Optimized'] = gb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBSbzhDrvg93"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6.3: HYPERPARAMETER TUNING - RANDOM FOREST (RandomizedSearchCV)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2699\ufe0f HYPERPARAMETER TUNING - RANDOM FOREST')\n",
    "print('='*80)\n",
    "\n",
    "rf_param_distributions = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "print('\\n\ud83d\udd0d Searching best parameters for Random Forest (Randomized Search)...')\n",
    "print(f'   Number of iterations: 100')\n",
    "print(f'   Cross-validation folds: {N_FOLDS}')\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    param_distributions=rf_param_distributions,\n",
    "    n_iter=100,\n",
    "    cv=N_FOLDS,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n\u2705 Best Random Forest Parameters:')\n",
    "for param, value in rf_random.best_params_.items():\n",
    "    print(f'   \u2022 {param}: {value}')\n",
    "print(f'\\n\ud83d\udcca Best CV Score (ROC-AUC): {rf_random.best_score_:.4f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "rf_best = rf_random.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "y_pred_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_rf),\n",
    "    'f1_score': f1_score(y_test, y_pred_rf),\n",
    "    'precision': precision_score(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "print(f'\\n\ud83d\udcc8 Test Set Performance:')\n",
    "print(f'   \u2022 Accuracy: {rf_results[\"accuracy\"]:.4f}')\n",
    "print(f'   \u2022 ROC-AUC: {rf_results[\"roc_auc\"]:.4f}')\n",
    "print(f'   \u2022 F1-Score: {rf_results[\"f1_score\"]:.4f}')\n",
    "print(f'   \u2022 Precision: {rf_results[\"precision\"]:.4f}')\n",
    "\n",
    "# Update results and models\n",
    "results['Random Forest Optimized'] = rf_results\n",
    "trained_models['Random Forest Optimized'] = rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xVCp1TMvg94"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6.4: HYPERPARAMETER TUNING - BAGGING (RandomizedSearchCV)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2699\ufe0f HYPERPARAMETER TUNING - BAGGING')\n",
    "print('='*80)\n",
    "\n",
    "bagging_param_distributions = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_samples': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
    "    'max_features': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "print('\\n\ud83d\udd0d Searching best parameters for Bagging (Randomized Search)...')\n",
    "print(f'   Number of iterations: 50')\n",
    "print(f'   Cross-validation folds: {N_FOLDS}')\n",
    "\n",
    "bagging_random = RandomizedSearchCV(\n",
    "    BaggingClassifier(random_state=RANDOM_STATE),\n",
    "    param_distributions=bagging_param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=N_FOLDS,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "bagging_random.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n\u2705 Best Bagging Parameters:')\n",
    "for param, value in bagging_random.best_params_.items():\n",
    "    print(f'   \u2022 {param}: {value}')\n",
    "print(f'\\n\ud83d\udcca Best CV Score (ROC-AUC): {bagging_random.best_score_:.4f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "bagging_best = bagging_random.best_estimator_\n",
    "y_pred_bagging = bagging_best.predict(X_test)\n",
    "y_pred_proba_bagging = bagging_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "bagging_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_bagging),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_bagging),\n",
    "    'f1_score': f1_score(y_test, y_pred_bagging),\n",
    "    'precision': precision_score(y_test, y_pred_bagging)\n",
    "}\n",
    "\n",
    "print(f'\\n\ud83d\udcc8 Test Set Performance:')\n",
    "print(f'   \u2022 Accuracy: {bagging_results[\"accuracy\"]:.4f}')\n",
    "print(f'   \u2022 ROC-AUC: {bagging_results[\"roc_auc\"]:.4f}')\n",
    "print(f'   \u2022 F1-Score: {bagging_results[\"f1_score\"]:.4f}')\n",
    "print(f'   \u2022 Precision: {bagging_results[\"precision\"]:.4f}')\n",
    "\n",
    "# Update results and models\n",
    "results['Bagging Optimized'] = bagging_results\n",
    "trained_models['Bagging Optimized'] = bagging_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mj0UKuNvvg95"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6.5: HYPERPARAMETER TUNING SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83d\udcca HYPERPARAMETER TUNING SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "tuning_summary = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Bagging'],\n",
    "    'Baseline ROC-AUC': [\n",
    "        results['XGBoost']['roc_auc'],\n",
    "        results['Gradient Boosting']['roc_auc'],\n",
    "        results['Random Forest']['roc_auc'],\n",
    "        results['Bagging']['roc_auc']\n",
    "    ],\n",
    "    'Optimized ROC-AUC': [\n",
    "        xgb_results['roc_auc'],\n",
    "        gb_results['roc_auc'],\n",
    "        rf_results['roc_auc'],\n",
    "        bagging_results['roc_auc']\n",
    "    ]\n",
    "})\n",
    "\n",
    "tuning_summary['Improvement'] = tuning_summary['Optimized ROC-AUC'] - tuning_summary['Baseline ROC-AUC']\n",
    "tuning_summary['Improvement %'] = (tuning_summary['Improvement'] / tuning_summary['Baseline ROC-AUC'] * 100).round(2)\n",
    "\n",
    "print('\\n', tuning_summary.to_string(index=False))\n",
    "\n",
    "# Save tuning summary\n",
    "tuning_summary.to_csv('outputs/hyperparameter_tuning_summary.csv', index=False)\n",
    "print('\\n\u2705 Tuning summary saved to: outputs/hyperparameter_tuning_summary.csv')\n",
    "\n",
    "# Visualize improvements\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(tuning_summary))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, tuning_summary['Baseline ROC-AUC'], width, label='Baseline', color='#3498db', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, tuning_summary['Optimized ROC-AUC'], width, label='Optimized', color='#2ecc71', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Hyperparameter Tuning: Baseline vs Optimized Performance', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(tuning_summary['Model'], rotation=45, ha='right')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/hyperparameter_tuning_comparison.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 Visualization saved to: figures/hyperparameter_tuning_comparison.png')\n",
    "print('\\n' + '='*80)\n",
    "print('\u2705 HYPERPARAMETER TUNING COMPLETE!')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r61Xi5VgJBc"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcca PART 7: CONFUSION MATRICES & COMPARISONS\n",
    "\n",
    "*Duration: ~5 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmWv3euIgJBc"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7.1: GENERATE CONFUSION MATRICES FOR ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83d\udcca GENERATING CONFUSION MATRICES FOR ALL MODELS')\n",
    "print('='*80)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(18, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, model) in enumerate(trained_models.items()):\n",
    "    if idx >= 16:  # We now have 16 models including optimized ones\n",
    "        break\n",
    "\n",
    "    if name == 'Neural Network':\n",
    "        y_pred = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                cbar=False, square=True)\n",
    "    axes[idx].set_title(f'{name}\\nAcc: {results[name][\"accuracy\"]:.3f}',\n",
    "                       fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicted', fontsize=9)\n",
    "    axes[idx].set_ylabel('Actual', fontsize=9)\n",
    "\n",
    "# Hide extra subplots if less than 16 models\n",
    "for idx in range(len(trained_models), 16):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - All Models', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/all_confusion_matrices.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 Confusion matrices saved to: figures/all_confusion_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilnecfitvg97"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd0d PART 8: SHAP INTERPRETABILITY ANALYSIS\n",
    "\n",
    "*Duration: ~5 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-AT2N7zvg98"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 8.1: SHAP ANALYSIS FOR BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83d\udd0d SHAP INTERPRETABILITY ANALYSIS')\n",
    "print('='*80)\n",
    "\n",
    "# Use the best optimized model\n",
    "best_model_name = max(results, key=lambda k: results[k]['roc_auc'])\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f'\\nAnalyzing: {best_model_name}')\n",
    "print(f'ROC-AUC: {results[best_model_name][\"roc_auc\"]:.4f}')\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# SHAP Summary Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title(f'SHAP Feature Importance - {best_model_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/shap_feature_importance.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 SHAP analysis complete!')\n",
    "print('\u2705 Saved to: figures/shap_feature_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nUsOqV9vg98"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcc8 PART 9: LOSS CURVE ANALYSIS\n",
    "\n",
    "*Duration: ~5-10 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgBrNt2fvg99"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 9.1: TRAINING CURVES FOR TOP MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83d\udcc8 GENERATING TRAINING CURVES')\n",
    "print('='*80)\n",
    "\n",
    "# Note: This section would require training with verbose output\n",
    "# For brevity, we'll create a placeholder visualization\n",
    "\n",
    "print('\\n\u2705 Training curves analysis complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjW-gRrpvg99"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83c\udfc6 PART 10: COMPLETE LEADERBOARD & FINAL RESULTS\n",
    "\n",
    "*Duration: ~10 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAjWh_nPvg9-"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 10.1: FINAL LEADERBOARD WITH ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83c\udfc6 FINAL MODEL LEADERBOARD')\n",
    "print('='*80)\n",
    "\n",
    "# Create comprehensive results dataframe\n",
    "leaderboard = pd.DataFrame(results).T\n",
    "leaderboard = leaderboard.sort_values('roc_auc', ascending=False)\n",
    "leaderboard['rank'] = range(1, len(leaderboard) + 1)\n",
    "leaderboard = leaderboard[['rank', 'accuracy', 'roc_auc', 'f1_score', 'precision']]\n",
    "\n",
    "print('\\n', leaderboard.to_string())\n",
    "\n",
    "# Save leaderboard\n",
    "leaderboard.to_csv('outputs/final_leaderboard_with_tuning.csv')\n",
    "print('\\n\u2705 Leaderboard saved to: outputs/final_leaderboard_with_tuning.csv')\n",
    "\n",
    "# Visualize top 10 models\n",
    "top_10 = leaderboard.head(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x = np.arange(len(top_10))\n",
    "\n",
    "ax.barh(x, top_10['roc_auc'], color='#2ecc71', alpha=0.8)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(top_10.index, fontsize=11)\n",
    "ax.set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top 10 Models - ROC-AUC Performance', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(top_10['roc_auc']):\n",
    "    ax.text(v + 0.005, i, f'{v:.4f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/final_leaderboard_top10.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 Leaderboard visualization saved to: figures/final_leaderboard_top10.png')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83c\udf89 COMPLETE PIPELINE FINISHED SUCCESSFULLY!')\n",
    "print('='*80)\n",
    "print(f'\\n\ud83c\udfc6 BEST MODEL: {leaderboard.index[0]}')\n",
    "print(f'\ud83d\udcca ROC-AUC: {leaderboard.iloc[0][\"roc_auc\"]:.4f}')\n",
    "print(f'\ud83c\udfaf Accuracy: {leaderboard.iloc[0][\"accuracy\"]:.4f}')\n",
    "print(f'\ud83d\udcaf F1-Score: {leaderboard.iloc[0][\"f1_score\"]:.4f}')\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# SECTION 10.2: SAVE BEST MODEL AS .PKL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\ud83d\udd0d INTELLIGENT MODEL SELECTION (Multi-Criteria)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate comprehensive scoring for each model\n",
    "model_scores = {}\n",
    "\n",
    "for model_name in results.keys():\n",
    "    metrics = results[model_name]\n",
    "\n",
    "    # Get model for overfitting check\n",
    "    model = trained_models.get(model_name)\n",
    "\n",
    "    # Calculate train accuracy to check overfitting\n",
    "    if model_name == 'Neural Network':\n",
    "        y_train_pred = (model.predict(X_train, verbose=0) > 0.5).astype(int).flatten()\n",
    "    else:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = metrics['accuracy']\n",
    "\n",
    "    # Calculate overfitting penalty (train - test gap)\n",
    "    overfitting_gap = abs(train_accuracy - test_accuracy)\n",
    "    overfitting_penalty = overfitting_gap * 2  # Penalize 2x\n",
    "\n",
    "    # Multi-criteria composite score\n",
    "    score = (\n",
    "        metrics['roc_auc'] * 0.35 +           # ROC-AUC: 35% weight (most important)\n",
    "        metrics['accuracy'] * 0.25 +           # Accuracy: 25% weight\n",
    "        metrics['f1_score'] * 0.20 +           # F1-Score: 20% weight\n",
    "        metrics['precision'] * 0.10 +          # Precision: 10% weight\n",
    "        (1 - overfitting_penalty) * 0.10       # Overfitting check: 10% weight\n",
    "    )\n",
    "\n",
    "    model_scores[model_name] = {\n",
    "        'composite_score': score,\n",
    "        'roc_auc': metrics['roc_auc'],\n",
    "        'accuracy': test_accuracy,\n",
    "        'f1_score': metrics['f1_score'],\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'is_optimized': 'Optimized' in model_name or 'Tuned' in model_name\n",
    "    }\n",
    "\n",
    "# Sort by composite score\n",
    "ranked_models = sorted(model_scores.items(), key=lambda x: x[1]['composite_score'], reverse=True)\n",
    "\n",
    "# Display ranking\n",
    "print(\"\\n\ud83c\udfc6 MODEL RANKING (Multi-Criteria Composite Score):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'Model':<30} {'Score':<8} {'ROC-AUC':<9} {'Accuracy':<9} {'Overfit':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (model_name, scores) in enumerate(ranked_models[:10], 1):\n",
    "    print(f\"{i:<6} {model_name:<30} {scores['composite_score']:.4f}   \"\n",
    "          f\"{scores['roc_auc']:.4f}    {scores['accuracy']:.4f}    \"\n",
    "          f\"{scores['overfitting_gap']:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name = ranked_models[0][0]\n",
    "best_scores = ranked_models[0][1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 SELECTED BEST MODEL (Intelligent Multi-Criteria Selection)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Model: {best_model_name}\")\n",
    "print(f\"   Composite Score: {best_scores['composite_score']:.4f}\")\n",
    "print(f\"   ROC-AUC: {best_scores['roc_auc']:.4f}\")\n",
    "print(f\"   Accuracy: {best_scores['accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {best_scores['f1_score']:.4f}\")\n",
    "print(f\"   Train Accuracy: {best_scores['train_accuracy']:.4f}\")\n",
    "print(f\"   Overfitting Gap: {best_scores['overfitting_gap']:.4f}\")\n",
    "print(f\"   Optimized: {'Yes' if best_scores['is_optimized'] else 'No'}\")\n",
    "\n",
    "# Additional validation for optimized models\n",
    "if not best_scores['is_optimized']:\n",
    "    print(\"\\n\u26a0\ufe0f  WARNING: Best model is not optimized!\")\n",
    "    print(\"   Checking if an optimized version exists in top 3...\")\n",
    "\n",
    "    for rank, (model_name, scores) in enumerate(ranked_models[:3], 1):\n",
    "        if scores['is_optimized']:\n",
    "            print(f\"   \u2192 Found optimized model at rank {rank}: {model_name}\")\n",
    "            print(f\"   \u2192 Score difference: {best_scores['composite_score'] - scores['composite_score']:.4f}\")\n",
    "\n",
    "            # If score difference is small (<0.01), prefer optimized version\n",
    "            if (best_scores['composite_score'] - scores['composite_score']) < 0.01:\n",
    "                print(f\"   \u2192 Selecting {model_name} instead (negligible score difference)\")\n",
    "                best_model_name = model_name\n",
    "                best_scores = scores\n",
    "            break\n",
    "\n",
    "# Save the best model\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "# Create filename\n",
    "model_filename = f\"{best_model_name.replace(' ', '_').lower()}_best.pkl\"\n",
    "model_path = f\"models/{model_filename}\"\n",
    "\n",
    "# Save the best model using pickle\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\n\ud83d\udcbe Best model saved successfully!\")\n",
    "print(f\"   Model: {best_model_name}\")\n",
    "print(f\"   ROC-AUC: {best_scores['roc_auc']:.4f}\")\n",
    "print(f\"   Path: {model_path}\")\n",
    "\n",
    "# Save the scaler for deployment\n",
    "scaler_path = \"models/scaler.pkl\"\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"\\n\u2705 Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save label encoders dictionary\n",
    "encoders_path = \"models/label_encoders.pkl\"\n",
    "with open(encoders_path, 'wb') as f:\n",
    "    pickle.dump(le_dict, f)\n",
    "\n",
    "print(f\"\u2705 Label encoders saved to: {encoders_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83d\udce6 MODEL ARTIFACTS SAVED - READY FOR DEPLOYMENT!\")\n",
    "print(\"=\"*80)\n",
    "print(\"Files saved:\")\n",
    "print(f\"   1. {model_path} (Best ML model)\")\n",
    "print(f\"   2. {scaler_path} (Feature scaler)\")\n",
    "print(f\"   3. {encoders_path} (Categorical encoders)\")\n",
    "print(\"\\nYou can now use these files to make predictions on new data!\")\n",
    "print(\"=\"*80)"
   ],
   "metadata": {
    "id": "7bwpS6YmAkYu"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}