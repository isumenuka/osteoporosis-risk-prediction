{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWFh-8QnMkhG"
      },
      "source": [
        "# \ud83c\udfe5 OSTEOPOROSIS RISK PREDICTION - COMPLETE MASTER PIPELINE\n",
        "\n",
        "## \ud83c\udfaf All-in-One Comprehensive Machine Learning Workflow\n",
        "\n",
        "**Project:** Osteoporosis Risk Prediction  \n",
        "**Group:** DSGP Group 40  \n",
        "**Date:** January 2026  \n",
        "**Status:** \u2705 Production Ready  \n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udccb **Notebook Structure**\n",
        "\n",
        "This master notebook combines all 10 comprehensive sections into one unified workflow:\n",
        "\n",
        "1. \u2705 **Environment Setup** - Libraries & Configuration\n",
        "2. \u2705 **Data Preparation** - Loading & Initial Exploration\n",
        "3. \u2705 **Data Preprocessing** - Cleaning & Feature Engineering\n",
        "4. \u2705 **Model Training** - 12 ML Algorithms\n",
        "5. \u2705 **Gender-Specific Models** - Separate Male/Female XGBoost\n",
        "6. \u2705 **Hyperparameter Tuning** - Top 4 Models Optimization\n",
        "7. \u2705 **Confusion Matrices** - All Models with Comparison\n",
        "8. \u2705 **SHAP Analysis** - Advanced Explainability (5 visualization types)\n",
        "9. \u2705 **Loss Curve Analysis** - Top 4 Algorithms (8 visualization types)\n",
        "10. \u2705 **Complete Leaderboard** - All Models Ranked\n",
        "\n",
        "**Output Files:** 58+ visualizations + 9 CSV files  \n",
        "**Model Comparison:** 14 models evaluated with multiple metrics\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umdSZthyXVOh"
      },
      "source": [
        "## \ud83d\udcda TABLE OF CONTENTS\n",
        "\n",
        "| Section | Subsections |\n",
        "|---------|-------------|\n",
        "| **PART 1** | Environment & Libraries |\n",
        "| **PART 2** | Data Loading & Exploration |\n",
        "| **PART 3** | Data Cleaning & Features |\n",
        "| **PART 4** | Gender-Specific Modeling Pipelines (Train/Tune/Eval) |\n",
        "| **PART 5** | Confusion Matrices (Male vs Female) |\n",
        "| **PART 6** | SHAP Interpretability |\n",
        "| **PART 7** | Loss Curves |\n",
        "| **PART 8** | Final Leaderboards & Saving |\n",
        "| **Total** | Complete Gender-Specific ML Pipeline |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPZKjBUsMkhN"
      },
      "source": [
        "# \ud83d\udd27 PART 1: ENVIRONMENT SETUP & CONFIGURATION\n",
        "\n",
        "\n",
        "**Objective:** Import all required libraries and set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BtEn2RQgJBV"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.1: CORE LIBRARIES\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['lines.linewidth'] = 2\n",
        "\n",
        "print('\u2705 Core libraries imported successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_j5ECZWgJBW"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.2: SCIKIT-LEARN & MODELS\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report, roc_curve, auc, f1_score, precision_score\n",
        ")\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier,\n",
        "    AdaBoostClassifier, BaggingClassifier, StackingClassifier, ExtraTreesClassifier\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print('\u2705 Scikit-learn, XGBoost, and TensorFlow imported!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOHvAN1JgJBX"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.3: INTERPRETABILITY & UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "import shap\n",
        "import pickle\n",
        "import os\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('figures', exist_ok=True)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "print('\u2705 SHAP and utilities imported!')\n",
        "print('\u2705 Output directories created!')\n",
        "print('\\n' + '='*80)\n",
        "print('\ud83c\udfaf ALL LIBRARIES IMPORTED - READY TO PROCEED')\n",
        "print('='*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RrUqDJCgJBY"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION: Global Settings\n",
        "# ============================================================================\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "VALIDATION_SIZE = 0.2\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "N_ESTIMATORS = 200\n",
        "MAX_DEPTH = 5\n",
        "LEARNING_RATE = 0.05\n",
        "\n",
        "NN_EPOCHS = 100\n",
        "NN_BATCH_SIZE = 32\n",
        "NN_LEARNING_RATE = 0.001\n",
        "\n",
        "DPI = 300\n",
        "FIG_SIZE = (14, 8)\n",
        "\n",
        "print('\u2705 Configuration set:')\n",
        "print(f'   \u2022 Random Seed: {RANDOM_SEED}')\n",
        "print(f'   \u2022 Test/Train Split: {TEST_SIZE}')\n",
        "print(f'   \u2022 Cross-Validation Folds: {N_FOLDS}')\n",
        "print(f'   \u2022 Figure Resolution: {DPI} DPI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQQoF0XgJBY"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83d\udcca PART 2: DATA LOADING & EXPLORATION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO24R5A9gJBZ"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 2.1: LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "csv_path = 'data/osteoporosis_data.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f'\u2705 Dataset loaded successfully!')\n",
        "    print(f'   Shape: {df.shape} (rows, columns)')\n",
        "except FileNotFoundError:\n",
        "    print(f'\u274c File not found: {csv_path}')\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS_UCXahgJBa"
      },
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print('\\n' + '='*80)\n",
        "    print('DATA OVERVIEW')\n",
        "    print('='*80)\n",
        "    print(f'\\nShape: {df.shape}')\n",
        "    print(f'Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
        "    print(f'\\nColumns: {df.columns.tolist()}')\n",
        "    print(f'\\nMissing Values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2v2QeXDgJBa"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83e\uddf9 PART 3: DATA PREPROCESSING & FEATURE ENGINEERING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Ao8kRBgJBa"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 3.1: DATA PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "if df is not None:\n",
        "    # Create working copy\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Drop ID column (not useful for prediction)\n",
        "    df_processed = df_processed.drop('Id', axis=1)\n",
        "\n",
        "    # Handle missing values\n",
        "    # Fill categorical with 'Unknown'\n",
        "    categorical_cols = df_processed.select_dtypes(include='object').columns\n",
        "    for col in categorical_cols:\n",
        "        df_processed[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    le_dict = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col])\n",
        "        le_dict[col] = le\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df_processed.drop('Osteoporosis', axis=1)\n",
        "    y = df_processed['Osteoporosis']\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "\n",
        "    print('\u2705 Data preprocessing complete!')\n",
        "    print(f'   Training set: {X_train.shape}')\n",
        "    print(f'   Test set: {X_test.shape}')\n",
        "    print(f'   Features: {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ8PGu1j3IT1"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83d\udc68\u200d\u2695\ufe0f\ud83d\udc69\u200d\u2695\ufe0f PART 4: GENDER-SPECIFIC MODELING PIPELINES\n",
        "\n",
        "\n",
        "**Objective:** Train separate XGBoost models for male and female patients to improve prediction accuracy by accounting for biological differences in osteoporosis risk factors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5C0tAX83IT1"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.1: DEFINE MODEL TRAINING FUNCTIONS & HYPERPARAMETERS\n",
        "# ============================================================================\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_models_and_params():\n",
        "    # Returns tuple of (models_dict, params_dict)\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=2000),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "        'XGBoost': XGBClassifier(random_state=RANDOM_STATE, verbosity=0, eval_metric='logloss'),\n",
        "        'AdaBoost': AdaBoostClassifier(random_state=RANDOM_STATE),\n",
        "        'Bagging': BaggingClassifier(random_state=RANDOM_STATE),\n",
        "        'KNN': KNeighborsClassifier(),\n",
        "        'SVM': SVC(probability=True, random_state=RANDOM_STATE),\n",
        "        'Neural Network': 'NN_SPECIAL', # Handled separately\n",
        "        'Stacking': StackingClassifier(\n",
        "            estimators=[\n",
        "                ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
        "                ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
        "            ],\n",
        "            final_estimator=LogisticRegression()\n",
        "        ),\n",
        "        'Extra Trees': ExtraTreesClassifier(random_state=RANDOM_STATE)\n",
        "    }\n",
        "\n",
        "    # EXPANDED SEARCH SPACE\n",
        "    params = {\n",
        "        'Logistic Regression': {\n",
        "            'C': uniform(0.001, 100), # Much wider range\n",
        "            'solver': ['liblinear', 'lbfgs', 'saga'],\n",
        "            'penalty': ['l2'] # lbfgs only supports l2 or none. liblinear supports l1, l2.\n",
        "        },\n",
        "        'Decision Tree': {\n",
        "            'max_depth': randint(3, 50),\n",
        "            'min_samples_split': randint(2, 40),\n",
        "            'min_samples_leaf': randint(1, 20),\n",
        "            'criterion': ['gini', 'entropy']\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'n_estimators': randint(50, 500), # More trees\n",
        "            'max_depth': randint(5, 50),\n",
        "            'min_samples_split': randint(2, 20),\n",
        "            'min_samples_leaf': randint(1, 10),\n",
        "            'max_features': ['sqrt', 'log2', None],\n",
        "            'bootstrap': [True, False],\n",
        "            'class_weight': ['balanced', 'balanced_subsample', None]\n",
        "        },\n",
        "        'Gradient Boosting': {\n",
        "            'n_estimators': randint(50, 500),\n",
        "            'learning_rate': uniform(0.001, 0.5),\n",
        "            'max_depth': randint(3, 15),\n",
        "            'subsample': uniform(0.5, 0.5),\n",
        "            'max_features': ['sqrt', 'log2']\n",
        "        },\n",
        "        'XGBoost': {\n",
        "             # Important Tuning Parameters\n",
        "            'n_estimators': randint(50, 1000),\n",
        "            'learning_rate': uniform(0.001, 0.3),\n",
        "            'max_depth': randint(3, 15),\n",
        "            'subsample': uniform(0.5, 0.5),\n",
        "            'colsample_bytree': uniform(0.5, 0.5),\n",
        "            'gamma': uniform(0, 5), # Minimum loss reduction\n",
        "            'reg_alpha': uniform(0, 5), # L1 regularization\n",
        "            'reg_lambda': uniform(0, 5) # L2 regularization\n",
        "        },\n",
        "        'AdaBoost': {\n",
        "            'n_estimators': randint(50, 500),\n",
        "            'learning_rate': uniform(0.001, 2.0),\n",
        "            'algorithm': ['SAMME', 'SAMME.R']\n",
        "        },\n",
        "        'Bagging': {\n",
        "            'n_estimators': randint(10, 200),\n",
        "            'max_samples': uniform(0.5, 0.5),\n",
        "            'max_features': uniform(0.5, 0.5)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'n_neighbors': randint(3, 30),\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'p': [1, 2], # Manhattan vs Euclidean\n",
        "            'leaf_size': randint(10, 50)\n",
        "        },\n",
        "        'SVM': {\n",
        "            'C': uniform(0.1, 100),\n",
        "            'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
        "            'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "        },\n",
        "        'Stacking': {},\n",
        "        'Extra Trees': {\n",
        "            'n_estimators': randint(50, 500),\n",
        "            'max_depth': randint(5, 50),\n",
        "            'min_samples_split': randint(2, 20),\n",
        "            'min_samples_leaf': randint(1, 10),\n",
        "            'bootstrap': [True, False],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "    }\n",
        "    return models, params\n",
        "\n",
        "def train_evaluate_gender_models(X_tr, y_tr, X_te, y_te, gender_name):\n",
        "    print(f'\\n' + '='*60)\n",
        "    print(f'\u2699\ufe0f TUNING & TRAINING MODELS FOR: {gender_name.upper()}')\n",
        "    print('='*60)\n",
        "\n",
        "    models, params = get_models_and_params()\n",
        "    gender_results = {}\n",
        "    gender_trained_models = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f'   Processing {name}...')\n",
        "        try:\n",
        "            final_model = model\n",
        "            training_history = None\n",
        "\n",
        "            # 1. Hyperparameter Tuning or Special Handling\n",
        "            if name == 'Neural Network':\n",
        "                # Handle NN separately\n",
        "                final_model = keras.Sequential([\n",
        "                    layers.Dense(64, activation='relu', input_shape=(X_tr.shape[1],)),\n",
        "                    layers.Dropout(0.3),\n",
        "                    layers.Dense(32, activation='relu'),\n",
        "                    layers.Dropout(0.3),\n",
        "                    layers.Dense(1, activation='sigmoid')\n",
        "                ])\n",
        "                final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "                # Fit with history\n",
        "                history = final_model.fit(\n",
        "                    X_tr, y_tr,\n",
        "                    validation_data=(X_te, y_te),\n",
        "                    epochs=50, batch_size=32, verbose=0\n",
        "                )\n",
        "                training_history = history.history\n",
        "\n",
        "            elif name in params and params[name]:\n",
        "                print(f'      -> Tuning hyperparameters (Expanded Search)...')\n",
        "                search = RandomizedSearchCV(\n",
        "                    estimator=model,\n",
        "                    param_distributions=params[name],\n",
        "                    n_iter=20, # Increased iterations for better search\n",
        "                    cv=3,\n",
        "                    scoring='roc_auc',\n",
        "                    random_state=RANDOM_STATE,\n",
        "                    n_jobs=-1\n",
        "                )\n",
        "                search.fit(X_tr, y_tr)\n",
        "                final_model = search.best_estimator_\n",
        "                print(f'      -> Best Score: {search.best_score_:.4f}')\n",
        "                print(f'      -> Best Params: {search.best_params_}') # PRINT THE PARAMS\n",
        "\n",
        "                # REFIT WITH EVAL_SET FOR LOSS CURVES (Only if model supports it)\n",
        "                if name == 'XGBoost':\n",
        "                    print(f'      -> Refitting with eval_set for Loss Graphs...')\n",
        "                    final_model.fit(\n",
        "                        X_tr, y_tr,\n",
        "                        eval_set=[(X_tr, y_tr), (X_te, y_te)],\n",
        "                        verbose=False\n",
        "                    )\n",
        "                    training_history = final_model.evals_result()\n",
        "\n",
        "            else:\n",
        "                # Stacking, etc.\n",
        "                final_model.fit(X_tr, y_tr)\n",
        "\n",
        "            # 2. Evaluation\n",
        "            if name == 'Neural Network':\n",
        "                y_pred = (final_model.predict(X_te, verbose=0) > 0.5).astype(int).flatten()\n",
        "                y_pred_proba = final_model.predict(X_te, verbose=0).flatten()\n",
        "            else:\n",
        "                y_pred = final_model.predict(X_te)\n",
        "                if hasattr(final_model, 'predict_proba'):\n",
        "                    y_pred_proba = final_model.predict_proba(X_te)[:, 1]\n",
        "                else:\n",
        "                    y_pred_proba = y_pred\n",
        "\n",
        "            # 3. Overfitting Check\n",
        "            if name == 'Neural Network':\n",
        "                 y_train_pred = (final_model.predict(X_tr, verbose=0) > 0.5).astype(int).flatten()\n",
        "            else:\n",
        "                 y_train_pred = final_model.predict(X_tr)\n",
        "\n",
        "            train_acc = accuracy_score(y_tr, y_train_pred)\n",
        "            test_acc = accuracy_score(y_te, y_pred)\n",
        "            overfit_gap = train_acc - test_acc\n",
        "\n",
        "            # Metrics\n",
        "            roc = roc_auc_score(y_te, y_pred_proba)\n",
        "            f1 = f1_score(y_te, y_pred)\n",
        "\n",
        "            gender_results[name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'roc_auc': roc,\n",
        "                'f1_score': f1,\n",
        "                'train_accuracy': train_acc,\n",
        "                'overfit_gap': overfit_gap,\n",
        "                'model_obj': final_model,\n",
        "                'history': training_history\n",
        "            }\n",
        "            gender_trained_models[name] = final_model\n",
        "\n",
        "            print(f'      -> Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Gap: {overfit_gap:.4f} | AUC: {roc:.4f}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'   \u26a0\ufe0f Error training {name}: {str(e)}')\n",
        "\n",
        "    return gender_results, gender_trained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyZeKsxY3IT2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.2: GENDER-SPECIFIC TRAIN-TEST SPLIT\n",
        "# ============================================================================\n",
        "\n",
        "# 1. Filter Data\n",
        "male_indices = df_processed['Gender'] == 1  # Assuming 1 is Male, based on typical encoding or previous context\n",
        "female_indices = df_processed['Gender'] == 0 # Assuming 0 is Female\n",
        "# (Note: Verify your specific encoding if needed. Usually 1=Male, 0=Female or 0=Male, 1=Female in health datasets)\n",
        "# Let's stick to the previous notebook assumption: 0=Male, 1=Female if that was used in Part 6.1 previously.\n",
        "# Wait, looking at previous logs, user had: df_male = df_processed[df_processed['Gender'] == 0].copy()\n",
        "# So 0=Male, 1=Female.\n",
        "\n",
        "male_indices = df_processed['Gender'] == 0\n",
        "female_indices = df_processed['Gender'] == 1\n",
        "\n",
        "X_male = X_scaled[male_indices]\n",
        "y_male = y[male_indices]\n",
        "X_female = X_scaled[female_indices]\n",
        "y_female = y[female_indices]\n",
        "\n",
        "# 2. Split\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_male, y_male, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_male\n",
        ")\n",
        "\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
        "    X_female, y_female, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_female\n",
        ")\n",
        "\n",
        "print(f'\\n\u2705 Data Split Complete:')\n",
        "print(f'   Male Train: {X_train_m.shape}, Test: {X_test_m.shape}')\n",
        "print(f'   Female Train: {X_train_f.shape}, Test: {X_test_f.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmTT542I3IT2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.3: TUNE, TRAIN & EVALUATE MALE MODELS\n",
        "# ============================================================================\n",
        "\n",
        "male_results, male_models = train_evaluate_gender_models(X_train_m, y_train_m, X_test_m, y_test_m, 'Male')\n",
        "\n",
        "# Leaderboard to find the TRUE Best Male Model\n",
        "male_df = pd.DataFrame(male_results).T.drop('model_obj', axis=1).drop('history', axis=1)\n",
        "male_df = male_df.sort_values('roc_auc', ascending=False)\n",
        "print('\\n\ud83c\udfc6 MALE MODEL LEADERBOARD:')\n",
        "print(male_df)\n",
        "\n",
        "best_male_name = male_df.index[0]\n",
        "best_male_model = male_results[best_male_name]['model_obj']\n",
        "history = male_results[best_male_name]['history']\n",
        "\n",
        "print(f'\\n\u2728 Best Male Model: {best_male_name}')\n",
        "print(f'   ROC-AUC: {male_results[best_male_name][\"roc_auc\"]:.4f}')\n",
        "print(f'   Overfitting Gap: {male_results[best_male_name][\"overfit_gap\"]:.4f}')\n",
        "\n",
        "# GLOBAL STORAGE FOR PART 10\n",
        "global GLOBAL_BEST_MALE_MODEL, GLOBAL_BEST_MALE_NAME\n",
        "GLOBAL_BEST_MALE_MODEL = best_male_model\n",
        "GLOBAL_BEST_MALE_NAME = best_male_name\n",
        "print(f'\u2705 Stored best male model ({best_male_name}) for final saving in Part 10.')\n",
        "\n",
        "# 1. PLOT LOSS CURVE (If Available)\n",
        "if history:\n",
        "    training_loss = history['validation_0']['logloss']\n",
        "    validation_loss = history['validation_1']['logloss']\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(training_loss, label='Training Loss')\n",
        "    plt.plot(validation_loss, label='Validation Loss')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Log Loss')\n",
        "    plt.title(f'Male {best_male_name}: Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f'(Loss curve not available for {best_male_name})')\n",
        "\n",
        "# 2. PLOT ROC CURVE (ROG)\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "if hasattr(best_male_model, 'predict_proba'):\n",
        "    y_pred_proba = best_male_model.predict_proba(X_test_m)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test_m, y_pred_proba)\n",
        "    roc_auc_val = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_val:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Male Model ({best_male_name}): ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYUtInk63IT2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.4: TUNE, TRAIN & EVALUATE FEMALE MODELS\n",
        "# ============================================================================\n",
        "\n",
        "female_results, female_models = train_evaluate_gender_models(X_train_f, y_train_f, X_test_f, y_test_f, 'Female')\n",
        "\n",
        "# Leaderboard to find the TRUE Best Female Model\n",
        "female_df = pd.DataFrame(female_results).T.drop('model_obj', axis=1).drop('history', axis=1)\n",
        "female_df = female_df.sort_values('roc_auc', ascending=False)\n",
        "print('\\n\ud83c\udfc6 FEMALE MODEL LEADERBOARD:')\n",
        "print(female_df)\n",
        "\n",
        "best_female_name = female_df.index[0]\n",
        "best_female_model = female_results[best_female_name]['model_obj']\n",
        "history = female_results[best_female_name]['history']\n",
        "\n",
        "print(f'\\n\u2728 Best Female Model: {best_female_name}')\n",
        "print(f'   ROC-AUC: {female_results[best_female_name][\"roc_auc\"]:.4f}')\n",
        "print(f'   Overfitting Gap: {female_results[best_female_name][\"overfit_gap\"]:.4f}')\n",
        "\n",
        "# GLOBAL STORAGE FOR PART 10\n",
        "global GLOBAL_BEST_FEMALE_MODEL, GLOBAL_BEST_FEMALE_NAME\n",
        "GLOBAL_BEST_FEMALE_MODEL = best_female_model\n",
        "GLOBAL_BEST_FEMALE_NAME = best_female_name\n",
        "print(f'\u2705 Stored best female model ({best_female_name}) for final saving in Part 10.')\n",
        "\n",
        "# 1. PLOT LOSS CURVE (If Available)\n",
        "if history:\n",
        "    training_loss = history['validation_0']['logloss']\n",
        "    validation_loss = history['validation_1']['logloss']\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(training_loss, label='Training Loss')\n",
        "    plt.plot(validation_loss, label='Validation Loss')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Log Loss')\n",
        "    plt.title(f'Female {best_female_name}: Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f'(Loss curve not available for {best_female_name})')\n",
        "\n",
        "# 2. PLOT ROC CURVE (ROG)\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "if hasattr(best_female_model, 'predict_proba'):\n",
        "    y_pred_proba = best_female_model.predict_proba(X_test_f)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test_f, y_pred_proba)\n",
        "    roc_auc_val = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(fpr, tpr, color='purple', lw=2, label=f'ROC curve (area = {roc_auc_val:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Female Model ({best_female_name}): ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkR64jOa3IT3"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.5: SAVE BEST TUNED GENDER-SPECIFIC MODELS\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('\ud83d\udcbe SAVING BEST MODELS')\n",
        "print('='*60)\n",
        "\n",
        "# Save Male\n",
        "safe_male_name = best_male_name.replace(' ', '_').lower()\n",
        "with open(f'models/osteoporosis_male_{safe_male_name}_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_male_model, f)\n",
        "print(f'\u2705 Saved Best Male Model ({best_male_name}): models/osteoporosis_male_{safe_male_name}_model.pkl')\n",
        "\n",
        "# Save Female\n",
        "safe_female_name = best_female_name.replace(' ', '_').lower()\n",
        "with open(f'models/osteoporosis_female_{safe_female_name}_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_female_model, f)\n",
        "print(f'\u2705 Saved Best Female Model ({best_female_name}): models/osteoporosis_female_{safe_female_name}_model.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r61Xi5VgJBc"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83d\udcca PART 5: CONFUSION MATRICES & COMPARISONS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmWv3euIgJBc"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.1: GENERATE CONFUSION MATRICES (MALE vs FEMALE)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('\ud83d\udcca CONFUSION MATRICES: MALE vs FEMALE BEST MODELS')\n",
        "print('='*80)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Male Confusion Matrix\n",
        "y_pred_m = best_male_model.predict(X_test_m)\n",
        "cm_m = confusion_matrix(y_test_m, y_pred_m)\n",
        "sns.heatmap(cm_m, annot=True, fmt='d', cmap='Blues', ax=axes[0], square=True)\n",
        "axes[0].set_title(f'MALE: {best_male_name}\\nAcc: {accuracy_score(y_test_m, y_pred_m):.3f}', fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "# Female Confusion Matrix\n",
        "y_pred_f = best_female_model.predict(X_test_f)\n",
        "cm_f = confusion_matrix(y_test_f, y_pred_f)\n",
        "sns.heatmap(cm_f, annot=True, fmt='d', cmap='Reds', ax=axes[1], square=True)\n",
        "axes[1].set_title(f'FEMALE: {best_female_name}\\nAcc: {accuracy_score(y_test_f, y_pred_f):.3f}', fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('Confusion Matrices Comparison', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/gender_confusion_matrices.png', dpi=DPI)\n",
        "plt.show()\n",
        "\n",
        "print('\\n\u2705 Confusion matrices saved to: figures/gender_confusion_matrices.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilnecfitvg97"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83d\udd0d PART 6: SHAP INTERPRETABILITY ANALYSIS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-AT2N7zvg98"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 6.1: SHAP ANALYSIS (MALE vs FEMALE)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('\ud83d\udd0d SHAP ANALYSIS: FEATURE IMPORTANCE BY GENDER')\n",
        "print('='*80)\n",
        "\n",
        "# MALE SHAP\n",
        "print(f'\\nAnalyzing MALE Model: {best_male_name}')\n",
        "try:\n",
        "    explainer_m = shap.TreeExplainer(best_male_model)\n",
        "    shap_values_m = explainer_m.shap_values(X_test_m)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values_m, X_test_m, plot_type=\"bar\", show=False)\n",
        "    plt.title(f'MALE Feature Importance ({best_male_name})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Skipping SHAP for Male model: {e}\")\n",
        "\n",
        "# FEMALE SHAP\n",
        "print(f'\\nAnalyzing FEMALE Model: {best_female_name}')\n",
        "try:\n",
        "    explainer_f = shap.TreeExplainer(best_female_model)\n",
        "    shap_values_f = explainer_f.shap_values(X_test_f)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values_f, X_test_f, plot_type=\"bar\", show=False)\n",
        "    plt.title(f'FEMALE Feature Importance ({best_female_name})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Skipping SHAP for Female model: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nUsOqV9vg98"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83d\udcc8 PART 7: LOSS CURVE ANALYSIS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgBrNt2fvg99"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 7.1: TRAINING LOSS CURVES\n",
        "# ============================================================================\n",
        "# Note: Loss curves were generated during training in Part 4.\n",
        "# Refer to the plots generated directly after the training loops.\n",
        "print(\"\u2705 Loss curves for XGBoost/NN models were displayed during training in Part 4.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjW-gRrpvg99"
      },
      "source": [
        "---\n",
        "\n",
        "# \ud83c\udfc6 PART 8: COMPLETE LEADERBOARD & FINAL RESULTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAjWh_nPvg9-"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 8.1: FINAL GENDER-SPECIFIC LEADERBOARDS\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('\ud83c\udfc6 MALE MODEL LEADERBOARD')\n",
        "print('='*80)\n",
        "print(male_df)\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('\ud83c\udfc6 FEMALE MODEL LEADERBOARD')\n",
        "print('='*80)\n",
        "print(female_df)\n",
        "\n",
        "male_df.to_csv('outputs/male_leaderboard.csv')\n",
        "female_df.to_csv('outputs/female_leaderboard.csv')\n",
        "print('\\n\u2705 Leaderboards saved to CSV.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 8.2: SAVE BEST MODEL AS .PKL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"\ud83d\udce6 MODEL ARTIFACTS SAVED\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save the scaler for deployment\n",
        "scaler_path = \"models/scaler.pkl\"\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f\"\\n\u2705 Scaler saved to: {scaler_path}\")\n",
        "\n",
        "# Save label encoders dictionary\n",
        "encoders_path = \"models/label_encoders.pkl\"\n",
        "with open(encoders_path, 'wb') as f:\n",
        "    pickle.dump(le_dict, f)\n",
        "\n",
        "print(f\"\u2705 Label encoders saved to: {encoders_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\ud83d\udcbe FINAL SAVING: BEST GENDER-SPECIFIC MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save Male\n",
        "if 'GLOBAL_BEST_MALE_MODEL' in globals():\n",
        "    m_name = GLOBAL_BEST_MALE_NAME.replace(' ', '_').lower() if 'GLOBAL_BEST_MALE_NAME' in globals() else 'model'\n",
        "    path = f'models/osteoporosis_male_{m_name}_model.pkl'\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(GLOBAL_BEST_MALE_MODEL, f)\n",
        "    print(f\"\u2705 Saved MALE Model: {path}\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f GLOBAL_BEST_MALE_MODEL not found. Did you run Part 5?\")\n",
        "\n",
        "# Save Female\n",
        "if 'GLOBAL_BEST_FEMALE_MODEL' in globals():\n",
        "    f_name = GLOBAL_BEST_FEMALE_NAME.replace(' ', '_').lower() if 'GLOBAL_BEST_FEMALE_NAME' in globals() else 'model'\n",
        "    path = f'models/osteoporosis_female_{f_name}_model.pkl'\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(GLOBAL_BEST_FEMALE_MODEL, f)\n",
        "    print(f\"\u2705 Saved FEMALE Model: {path}\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f GLOBAL_BEST_FEMALE_MODEL not found. Did you run Part 5?\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ],
      "metadata": {
        "id": "7bwpS6YmAkYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}