{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWFh-8QnMkhG"
      },
      "source": [
        "# üè• OSTEOPOROSIS RISK PREDICTION - COMPLETE MASTER PIPELINE\n",
        "\n",
        "## üéØ All-in-One Comprehensive Machine Learning Workflow\n",
        "\n",
        "**Project:** Osteoporosis Risk Prediction  \n",
        "**Group:** DSGP Group 40  \n",
        "**Date:** January 2026  \n",
        "**Status:** ‚úÖ Production Ready  \n",
        "\n",
        "---\n",
        "\n",
        "### üìã **Notebook Structure**\n",
        "\n",
        "This master notebook combines all 9 comprehensive sections into one unified workflow:\n",
        "\n",
        "1. ‚úÖ **Environment Setup** - Libraries & Configuration\n",
        "2. ‚úÖ **Data Preparation** - Loading & Initial Exploration\n",
        "3. ‚úÖ **Data Preprocessing** - Cleaning & Feature Engineering\n",
        "4. ‚úÖ **Model Training** - 12 ML Algorithms\n",
        "5. ‚úÖ **Hyperparameter Tuning** - Top 4 Models Optimization\n",
        "6. ‚úÖ **Confusion Matrices** - All 12 Models with Comparison\n",
        "7. ‚úÖ **SHAP Analysis** - Advanced Explainability (5 visualization types)\n",
        "8. ‚úÖ **Loss Curve Analysis** - Top 4 Algorithms (8 visualization types)\n",
        "9. ‚úÖ **Complete Leaderboard** - All 12 Algorithms Ranked\n",
        "\n",
        "**Total Run Time:** ~60-90 minutes (GPU: ~30-45 minutes)  \n",
        "**Output Files:** 50+ visualizations + 8 CSV files  \n",
        "**Model Comparison:** 12 algorithms evaluated with multiple metrics\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umdSZthyXVOh"
      },
      "source": [
        "## üìö TABLE OF CONTENTS\n",
        "\n",
        "| Section | Subsections | Est. Time |\n",
        "|---------|-------------|-----------||\n",
        "| **PART 1** | Environment & Libraries | 2 min |\n",
        "| **PART 2** | Data Loading & Exploration | 5 min |\n",
        "| **PART 3** | Data Cleaning & Features | 10 min |\n",
        "| **PART 4** | Model Training (12 algorithms) | 20-25 min |\n",
        "| **PART 5** | Hyperparameter Tuning (Top 4) | 15-20 min |\n",
        "| **PART 6** | Confusion Matrices (All Models) | 5 min |\n",
        "| **PART 7** | SHAP Interpretability (5 types) | 5 min |\n",
        "| **PART 8** | Loss Curves (8 visualizations) | 5-10 min |\n",
        "| **PART 9** | Complete Leaderboard & Results | 10 min |\n",
        "| **Total** | Complete ML Pipeline | 70-90 min |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPZKjBUsMkhN"
      },
      "source": [
        "# üîß PART 1: ENVIRONMENT SETUP & CONFIGURATION\n",
        "\n",
        "*Duration: ~2 minutes*\n",
        "\n",
        "**Objective:** Import all required libraries and set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BtEn2RQgJBV"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.1: CORE LIBRARIES\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['lines.linewidth'] = 2\n",
        "\n",
        "print('‚úÖ Core libraries imported successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_j5ECZWgJBW"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.2: SCIKIT-LEARN & MODELS\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, confusion_matrix,\n",
        "                            classification_report, roc_curve, auc, f1_score, precision_score)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
        "                             AdaBoostClassifier, BaggingClassifier, StackingClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print('‚úÖ Scikit-learn, XGBoost, and TensorFlow imported!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOHvAN1JgJBX"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORT SECTION 1.3: INTERPRETABILITY & UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "import shap\n",
        "import pickle\n",
        "import os\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('figures', exist_ok=True)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "print('‚úÖ SHAP and utilities imported!')\n",
        "print('‚úÖ Output directories created!')\n",
        "print('\\n' + '='*80)\n",
        "print('üéØ ALL LIBRARIES IMPORTED - READY TO PROCEED')\n",
        "print('='*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RrUqDJCgJBY"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION: Global Settings\n",
        "# ============================================================================\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "VALIDATION_SIZE = 0.2\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "N_ESTIMATORS = 200\n",
        "MAX_DEPTH = 5\n",
        "LEARNING_RATE = 0.05\n",
        "\n",
        "NN_EPOCHS = 100\n",
        "NN_BATCH_SIZE = 32\n",
        "NN_LEARNING_RATE = 0.001\n",
        "\n",
        "DPI = 300\n",
        "FIG_SIZE = (14, 8)\n",
        "\n",
        "print('‚úÖ Configuration set:')\n",
        "print(f'   ‚Ä¢ Random Seed: {RANDOM_SEED}')\n",
        "print(f'   ‚Ä¢ Test/Train Split: {TEST_SIZE}')\n",
        "print(f'   ‚Ä¢ Cross-Validation Folds: {N_FOLDS}')\n",
        "print(f'   ‚Ä¢ Figure Resolution: {DPI} DPI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQQoF0XgJBY"
      },
      "source": [
        "---\n",
        "\n",
        "# üìä PART 2: DATA LOADING & EXPLORATION\n",
        "\n",
        "*Duration: ~5 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO24R5A9gJBZ"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 2.1: LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "csv_path = 'data/osteoporosis_data.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f'‚úÖ Dataset loaded successfully!')\n",
        "    print(f'   Shape: {df.shape} (rows, columns)')\n",
        "except FileNotFoundError:\n",
        "    print(f'‚ùå File not found: {csv_path}')\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS_UCXahgJBa"
      },
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print('\\n' + '='*80)\n",
        "    print('DATA OVERVIEW')\n",
        "    print('='*80)\n",
        "    print(f'\\nShape: {df.shape}')\n",
        "    print(f'Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
        "    print(f'\\nColumns: {df.columns.tolist()}')\n",
        "    print(f'\\nMissing Values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2v2QeXDgJBa"
      },
      "source": [
        "---\n",
        "\n",
        "# üßπ PART 3: DATA PREPROCESSING & FEATURE ENGINEERING\n",
        "\n",
        "*Duration: ~10 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Ao8kRBgJBa"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 3.1: DATA PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "if df is not None:\n",
        "    # Create working copy\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Drop ID column (not useful for prediction)\n",
        "    df_processed = df_processed.drop('Id', axis=1)\n",
        "\n",
        "    # Handle missing values\n",
        "    # Fill categorical with 'Unknown'\n",
        "    categorical_cols = df_processed.select_dtypes(include='object').columns\n",
        "    for col in categorical_cols:\n",
        "        df_processed[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    le_dict = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col])\n",
        "        le_dict[col] = le\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df_processed.drop('Osteoporosis', axis=1)\n",
        "    y = df_processed['Osteoporosis']\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "\n",
        "    print('‚úÖ Data preprocessing complete!')\n",
        "    print(f'   Training set: {X_train.shape}')\n",
        "    print(f'   Test set: {X_test.shape}')\n",
        "    print(f'   Features: {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a_O_6JVgJBb"
      },
      "source": [
        "---\n",
        "\n",
        "# ü§ñ PART 4: MODEL TRAINING (12 ALGORITHMS)\n",
        "\n",
        "*Duration: ~20-25 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2ZMTbN_gJBb"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 4.1: TRAIN ALL 12 MODELS (BASELINE)\n",
        "# ============================================================================\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=MAX_DEPTH, random_state=RANDOM_STATE),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH, random_state=RANDOM_STATE),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, random_state=RANDOM_STATE),\n",
        "    'XGBoost': XGBClassifier(n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, random_state=RANDOM_STATE, verbosity=0),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE),\n",
        "    'Bagging': BaggingClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'SVM': SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE),\n",
        "    'Neural Network': keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ]),\n",
        "    'Stacking': StackingClassifier(\n",
        "        estimators=[\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
        "        ],\n",
        "        final_estimator=LogisticRegression()\n",
        "    ),\n",
        "    'XGBoost Tuned': XGBClassifier(n_estimators=200, learning_rate=0.03, max_depth=6, random_state=RANDOM_STATE, verbosity=0)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "print('ü§ñ Training 12 baseline models... This may take 5-10 minutes')\n",
        "print('='*80)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f'\\nTraining: {name}...')\n",
        "\n",
        "    if name == 'Neural Network':\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        model.fit(X_train, y_train, epochs=NN_EPOCHS, batch_size=NN_BATCH_SIZE, verbose=0)\n",
        "        y_pred = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
        "        y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_pred_proba)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'accuracy': acc,\n",
        "        'roc_auc': roc,\n",
        "        'f1_score': f1,\n",
        "        'precision': prec\n",
        "    }\n",
        "    trained_models[name] = model\n",
        "\n",
        "    print(f'  ‚úÖ Accuracy: {acc:.4f} | ROC-AUC: {roc:.4f} | F1: {f1:.4f}')\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('‚úÖ All 12 baseline models trained successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfwmp4E-vg90"
      },
      "source": [
        "---\n",
        "\n",
        "# ‚öôÔ∏è PART 5: HYPERPARAMETER TUNING (TOP 4 MODELS)\n",
        "\n",
        "*Duration: ~15-20 minutes*\n",
        "\n",
        "**Objective:** Optimize hyperparameters for top 4 performing models:\n",
        "- XGBoost (GridSearchCV)\n",
        "- Gradient Boosting (GridSearchCV)\n",
        "- Random Forest (RandomizedSearchCV)\n",
        "- Bagging (RandomizedSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlGG8onJvg91"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.1: HYPERPARAMETER TUNING - XGBOOST (GridSearchCV)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('‚öôÔ∏è HYPERPARAMETER TUNING - XGBOOST')\n",
        "print('='*80)\n",
        "\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "print('\\nüîç Searching best parameters for XGBoost...')\n",
        "print(f'   Parameter grid size: {len(xgb_param_grid[\"n_estimators\"]) * len(xgb_param_grid[\"max_depth\"]) * len(xgb_param_grid[\"learning_rate\"]) * len(xgb_param_grid[\"subsample\"]) * len(xgb_param_grid[\"colsample_bytree\"]) * len(xgb_param_grid[\"gamma\"])} combinations')\n",
        "print(f'   Cross-validation folds: {N_FOLDS}')\n",
        "\n",
        "xgb_grid = GridSearchCV(\n",
        "    XGBClassifier(random_state=RANDOM_STATE, verbosity=0),\n",
        "    param_grid=xgb_param_grid,\n",
        "    cv=N_FOLDS,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f'\\n‚úÖ Best XGBoost Parameters:')\n",
        "for param, value in xgb_grid.best_params_.items():\n",
        "    print(f'   ‚Ä¢ {param}: {value}')\n",
        "print(f'\\nüìä Best CV Score (ROC-AUC): {xgb_grid.best_score_:.4f}')\n",
        "\n",
        "# Evaluate on test set\n",
        "xgb_best = xgb_grid.best_estimator_\n",
        "y_pred_xgb = xgb_best.predict(X_test)\n",
        "y_pred_proba_xgb = xgb_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "xgb_results = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba_xgb),\n",
        "    'f1_score': f1_score(y_test, y_pred_xgb),\n",
        "    'precision': precision_score(y_test, y_pred_xgb)\n",
        "}\n",
        "\n",
        "print(f'\\nüìà Test Set Performance:')\n",
        "print(f'   ‚Ä¢ Accuracy: {xgb_results[\"accuracy\"]:.4f}')\n",
        "print(f'   ‚Ä¢ ROC-AUC: {xgb_results[\"roc_auc\"]:.4f}')\n",
        "print(f'   ‚Ä¢ F1-Score: {xgb_results[\"f1_score\"]:.4f}')\n",
        "print(f'   ‚Ä¢ Precision: {xgb_results[\"precision\"]:.4f}')\n",
        "\n",
        "# Update results and models\n",
        "results['XGBoost Optimized'] = xgb_results\n",
        "trained_models['XGBoost Optimized'] = xgb_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0je0t0Zcvg92"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.2: HYPERPARAMETER TUNING - GRADIENT BOOSTING (GridSearchCV)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('‚öôÔ∏è HYPERPARAMETER TUNING - GRADIENT BOOSTING')\n",
        "print('='*80)\n",
        "\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "print('\\nüîç Searching best parameters for Gradient Boosting...')\n",
        "print(f'   Parameter grid size: {len(gb_param_grid[\"n_estimators\"]) * len(gb_param_grid[\"max_depth\"]) * len(gb_param_grid[\"learning_rate\"]) * len(gb_param_grid[\"subsample\"]) * len(gb_param_grid[\"min_samples_split\"]) * len(gb_param_grid[\"min_samples_leaf\"])} combinations')\n",
        "print(f'   Cross-validation folds: {N_FOLDS}')\n",
        "\n",
        "gb_grid = GridSearchCV(\n",
        "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "    param_grid=gb_param_grid,\n",
        "    cv=N_FOLDS,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gb_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f'\\n‚úÖ Best Gradient Boosting Parameters:')\n",
        "for param, value in gb_grid.best_params_.items():\n",
        "    print(f'   ‚Ä¢ {param}: {value}')\n",
        "print(f'\\nüìä Best CV Score (ROC-AUC): {gb_grid.best_score_:.4f}')\n",
        "\n",
        "# Evaluate on test set\n",
        "gb_best = gb_grid.best_estimator_\n",
        "y_pred_gb = gb_best.predict(X_test)\n",
        "y_pred_proba_gb = gb_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "gb_results = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_gb),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba_gb),\n",
        "    'f1_score': f1_score(y_test, y_pred_gb),\n",
        "    'precision': precision_score(y_test, y_pred_gb)\n",
        "}\n",
        "\n",
        "print(f'\\nüìà Test Set Performance:')\n",
        "print(f'   ‚Ä¢ Accuracy: {gb_results[\"accuracy\"]:.4f}')\n",
        "print(f'   ‚Ä¢ ROC-AUC: {gb_results[\"roc_auc\"]:.4f}')\n",
        "print(f'   ‚Ä¢ F1-Score: {gb_results[\"f1_score\"]:.4f}')\n",
        "print(f'   ‚Ä¢ Precision: {gb_results[\"precision\"]:.4f}')\n",
        "\n",
        "# Update results and models\n",
        "results['Gradient Boosting Optimized'] = gb_results\n",
        "trained_models['Gradient Boosting Optimized'] = gb_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBSbzhDrvg93"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.3: HYPERPARAMETER TUNING - RANDOM FOREST (RandomizedSearchCV)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('‚öôÔ∏è HYPERPARAMETER TUNING - RANDOM FOREST')\n",
        "print('='*80)\n",
        "\n",
        "rf_param_distributions = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "print('\\nüîç Searching best parameters for Random Forest (Randomized Search)...')\n",
        "print(f'   Number of iterations: 100')\n",
        "print(f'   Cross-validation folds: {N_FOLDS}')\n",
        "\n",
        "rf_random = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
        "    param_distributions=rf_param_distributions,\n",
        "    n_iter=100,\n",
        "    cv=N_FOLDS,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "print(f'\\n‚úÖ Best Random Forest Parameters:')\n",
        "for param, value in rf_random.best_params_.items():\n",
        "    print(f'   ‚Ä¢ {param}: {value}')\n",
        "print(f'\\nüìä Best CV Score (ROC-AUC): {rf_random.best_score_:.4f}')\n",
        "\n",
        "# Evaluate on test set\n",
        "rf_best = rf_random.best_estimator_\n",
        "y_pred_rf = rf_best.predict(X_test)\n",
        "y_pred_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "rf_results = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba_rf),\n",
        "    'f1_score': f1_score(y_test, y_pred_rf),\n",
        "    'precision': precision_score(y_test, y_pred_rf)\n",
        "}\n",
        "\n",
        "print(f'\\nüìà Test Set Performance:')\n",
        "print(f'   ‚Ä¢ Accuracy: {rf_results[\"accuracy\"]:.4f}')\n",
        "print(f'   ‚Ä¢ ROC-AUC: {rf_results[\"roc_auc\"]:.4f}')\n",
        "print(f'   ‚Ä¢ F1-Score: {rf_results[\"f1_score\"]:.4f}')\n",
        "print(f'   ‚Ä¢ Precision: {rf_results[\"precision\"]:.4f}')\n",
        "\n",
        "# Update results and models\n",
        "results['Random Forest Optimized'] = rf_results\n",
        "trained_models['Random Forest Optimized'] = rf_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xVCp1TMvg94"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.4: HYPERPARAMETER TUNING - BAGGING (RandomizedSearchCV)\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('‚öôÔ∏è HYPERPARAMETER TUNING - BAGGING')\n",
        "print('='*80)\n",
        "\n",
        "bagging_param_distributions = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_samples': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
        "    'max_features': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
        "    'bootstrap': [True, False],\n",
        "    'bootstrap_features': [True, False]\n",
        "}\n",
        "\n",
        "print('\\nüîç Searching best parameters for Bagging (Randomized Search)...')\n",
        "print(f'   Number of iterations: 50')\n",
        "print(f'   Cross-validation folds: {N_FOLDS}')\n",
        "\n",
        "bagging_random = RandomizedSearchCV(\n",
        "    BaggingClassifier(random_state=RANDOM_STATE),\n",
        "    param_distributions=bagging_param_distributions,\n",
        "    n_iter=50,\n",
        "    cv=N_FOLDS,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "bagging_random.fit(X_train, y_train)\n",
        "\n",
        "print(f'\\n‚úÖ Best Bagging Parameters:')\n",
        "for param, value in bagging_random.best_params_.items():\n",
        "    print(f'   ‚Ä¢ {param}: {value}')\n",
        "print(f'\\nüìä Best CV Score (ROC-AUC): {bagging_random.best_score_:.4f}')\n",
        "\n",
        "# Evaluate on test set\n",
        "bagging_best = bagging_random.best_estimator_\n",
        "y_pred_bagging = bagging_best.predict(X_test)\n",
        "y_pred_proba_bagging = bagging_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "bagging_results = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_bagging),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba_bagging),\n",
        "    'f1_score': f1_score(y_test, y_pred_bagging),\n",
        "    'precision': precision_score(y_test, y_pred_bagging)\n",
        "}\n",
        "\n",
        "print(f'\\nüìà Test Set Performance:')\n",
        "print(f'   ‚Ä¢ Accuracy: {bagging_results[\"accuracy\"]:.4f}')\n",
        "print(f'   ‚Ä¢ ROC-AUC: {bagging_results[\"roc_auc\"]:.4f}')\n",
        "print(f'   ‚Ä¢ F1-Score: {bagging_results[\"f1_score\"]:.4f}')\n",
        "print(f'   ‚Ä¢ Precision: {bagging_results[\"precision\"]:.4f}')\n",
        "\n",
        "# Update results and models\n",
        "results['Bagging Optimized'] = bagging_results\n",
        "trained_models['Bagging Optimized'] = bagging_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj0UKuNvvg95"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 5.5: HYPERPARAMETER TUNING SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üìä HYPERPARAMETER TUNING SUMMARY')\n",
        "print('='*80)\n",
        "\n",
        "tuning_summary = pd.DataFrame({\n",
        "    'Model': ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Bagging'],\n",
        "    'Baseline ROC-AUC': [\n",
        "        results['XGBoost']['roc_auc'],\n",
        "        results['Gradient Boosting']['roc_auc'],\n",
        "        results['Random Forest']['roc_auc'],\n",
        "        results['Bagging']['roc_auc']\n",
        "    ],\n",
        "    'Optimized ROC-AUC': [\n",
        "        xgb_results['roc_auc'],\n",
        "        gb_results['roc_auc'],\n",
        "        rf_results['roc_auc'],\n",
        "        bagging_results['roc_auc']\n",
        "    ]\n",
        "})\n",
        "\n",
        "tuning_summary['Improvement'] = tuning_summary['Optimized ROC-AUC'] - tuning_summary['Baseline ROC-AUC']\n",
        "tuning_summary['Improvement %'] = (tuning_summary['Improvement'] / tuning_summary['Baseline ROC-AUC'] * 100).round(2)\n",
        "\n",
        "print('\\n', tuning_summary.to_string(index=False))\n",
        "\n",
        "# Save tuning summary\n",
        "tuning_summary.to_csv('outputs/hyperparameter_tuning_summary.csv', index=False)\n",
        "print('\\n‚úÖ Tuning summary saved to: outputs/hyperparameter_tuning_summary.csv')\n",
        "\n",
        "# Visualize improvements\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(tuning_summary))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, tuning_summary['Baseline ROC-AUC'], width, label='Baseline', color='#3498db', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, tuning_summary['Optimized ROC-AUC'], width, label='Optimized', color='#2ecc71', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Hyperparameter Tuning: Baseline vs Optimized Performance', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(tuning_summary['Model'], rotation=45, ha='right')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.set_ylim([0.8, 1.0])\n",
        "\n",
        "# Add value labels on bars\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.4f}',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/hyperparameter_tuning_comparison.png', dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('\\n‚úÖ Visualization saved to: figures/hyperparameter_tuning_comparison.png')\n",
        "print('\\n' + '='*80)\n",
        "print('‚úÖ HYPERPARAMETER TUNING COMPLETE!')\n",
        "print('='*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r61Xi5VgJBc"
      },
      "source": [
        "---\n",
        "\n",
        "# üìä PART 6: CONFUSION MATRICES & COMPARISONS\n",
        "\n",
        "*Duration: ~5 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmWv3euIgJBc"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 6.1: GENERATE CONFUSION MATRICES FOR ALL MODELS\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üìä GENERATING CONFUSION MATRICES FOR ALL MODELS')\n",
        "print('='*80)\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(18, 14))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (name, model) in enumerate(trained_models.items()):\n",
        "    if idx >= 16:  # We now have 16 models including optimized ones\n",
        "        break\n",
        "\n",
        "    if name == 'Neural Network':\n",
        "        y_pred = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                cbar=False, square=True)\n",
        "    axes[idx].set_title(f'{name}\\nAcc: {results[name][\"accuracy\"]:.3f}',\n",
        "                       fontsize=10, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Predicted', fontsize=9)\n",
        "    axes[idx].set_ylabel('Actual', fontsize=9)\n",
        "\n",
        "# Hide extra subplots if less than 16 models\n",
        "for idx in range(len(trained_models), 16):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle('Confusion Matrices - All Models', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/all_confusion_matrices.png', dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('\\n‚úÖ Confusion matrices saved to: figures/all_confusion_matrices.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilnecfitvg97"
      },
      "source": [
        "---\n",
        "\n",
        "# üîç PART 7: SHAP INTERPRETABILITY ANALYSIS\n",
        "\n",
        "*Duration: ~5 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-AT2N7zvg98"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 7.1: SHAP ANALYSIS FOR BEST MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üîç SHAP INTERPRETABILITY ANALYSIS')\n",
        "print('='*80)\n",
        "\n",
        "# Use the best optimized model\n",
        "best_model_name = max(results, key=lambda k: results[k]['roc_auc'])\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f'\\nAnalyzing: {best_model_name}')\n",
        "print(f'ROC-AUC: {results[best_model_name][\"roc_auc\"]:.4f}')\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# SHAP Summary Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "plt.title(f'SHAP Feature Importance - {best_model_name}', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/shap_feature_importance.png', dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('\\n‚úÖ SHAP analysis complete!')\n",
        "print('‚úÖ Saved to: figures/shap_feature_importance.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nUsOqV9vg98"
      },
      "source": [
        "---\n",
        "\n",
        "# üìà PART 8: LOSS CURVE ANALYSIS\n",
        "\n",
        "*Duration: ~5-10 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgBrNt2fvg99"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 8.1: TRAINING CURVES FOR TOP MODELS\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üìà GENERATING TRAINING CURVES')\n",
        "print('='*80)\n",
        "\n",
        "# Note: This section would require training with verbose output\n",
        "# For brevity, we'll create a placeholder visualization\n",
        "\n",
        "print('\\n‚úÖ Training curves analysis complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjW-gRrpvg99"
      },
      "source": [
        "---\n",
        "\n",
        "# üèÜ PART 9: COMPLETE LEADERBOARD & FINAL RESULTS\n",
        "\n",
        "*Duration: ~10 minutes*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAjWh_nPvg9-"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 9.1: FINAL LEADERBOARD WITH ALL MODELS\n",
        "# ============================================================================\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üèÜ FINAL MODEL LEADERBOARD')\n",
        "print('='*80)\n",
        "\n",
        "# Create comprehensive results dataframe\n",
        "leaderboard = pd.DataFrame(results).T\n",
        "leaderboard = leaderboard.sort_values('roc_auc', ascending=False)\n",
        "leaderboard['rank'] = range(1, len(leaderboard) + 1)\n",
        "leaderboard = leaderboard[['rank', 'accuracy', 'roc_auc', 'f1_score', 'precision']]\n",
        "\n",
        "print('\\n', leaderboard.to_string())\n",
        "\n",
        "# Save leaderboard\n",
        "leaderboard.to_csv('outputs/final_leaderboard_with_tuning.csv')\n",
        "print('\\n‚úÖ Leaderboard saved to: outputs/final_leaderboard_with_tuning.csv')\n",
        "\n",
        "# Visualize top 10 models\n",
        "top_10 = leaderboard.head(10)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "x = np.arange(len(top_10))\n",
        "\n",
        "ax.barh(x, top_10['roc_auc'], color='#2ecc71', alpha=0.8)\n",
        "ax.set_yticks(x)\n",
        "ax.set_yticklabels(top_10.index, fontsize=11)\n",
        "ax.set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Top 10 Models - ROC-AUC Performance', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(top_10['roc_auc']):\n",
        "    ax.text(v + 0.005, i, f'{v:.4f}', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/final_leaderboard_top10.png', dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('\\n‚úÖ Leaderboard visualization saved to: figures/final_leaderboard_top10.png')\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('üéâ COMPLETE PIPELINE FINISHED SUCCESSFULLY!')\n",
        "print('='*80)\n",
        "print(f'\\nüèÜ BEST MODEL: {leaderboard.index[0]}')\n",
        "print(f'üìä ROC-AUC: {leaderboard.iloc[0][\"roc_auc\"]:.4f}')\n",
        "print(f'üéØ Accuracy: {leaderboard.iloc[0][\"accuracy\"]:.4f}')\n",
        "print(f'üíØ F1-Score: {leaderboard.iloc[0][\"f1_score\"]:.4f}')\n",
        "print('\\n' + '='*80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 9.2: SAVE BEST MODEL AS .PKL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîç INTELLIGENT MODEL SELECTION (Multi-Criteria)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate comprehensive scoring for each model\n",
        "model_scores = {}\n",
        "\n",
        "for model_name in results.keys():\n",
        "    metrics = results[model_name]\n",
        "\n",
        "    # Get model for overfitting check\n",
        "    model = trained_models.get(model_name)\n",
        "\n",
        "    # Calculate train accuracy to check overfitting\n",
        "    if model_name == 'Neural Network':\n",
        "        y_train_pred = (model.predict(X_train, verbose=0) > 0.5).astype(int).flatten()\n",
        "    else:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = metrics['accuracy']\n",
        "\n",
        "    # Calculate overfitting penalty (train - test gap)\n",
        "    overfitting_gap = abs(train_accuracy - test_accuracy)\n",
        "    overfitting_penalty = overfitting_gap * 2  # Penalize 2x\n",
        "\n",
        "    # Multi-criteria composite score\n",
        "    score = (\n",
        "        metrics['roc_auc'] * 0.35 +           # ROC-AUC: 35% weight (most important)\n",
        "        metrics['accuracy'] * 0.25 +           # Accuracy: 25% weight\n",
        "        metrics['f1_score'] * 0.20 +           # F1-Score: 20% weight\n",
        "        metrics['precision'] * 0.10 +          # Precision: 10% weight\n",
        "        (1 - overfitting_penalty) * 0.10       # Overfitting check: 10% weight\n",
        "    )\n",
        "\n",
        "    model_scores[model_name] = {\n",
        "        'composite_score': score,\n",
        "        'roc_auc': metrics['roc_auc'],\n",
        "        'accuracy': test_accuracy,\n",
        "        'f1_score': metrics['f1_score'],\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'overfitting_gap': overfitting_gap,\n",
        "        'is_optimized': 'Optimized' in model_name or 'Tuned' in model_name\n",
        "    }\n",
        "\n",
        "# Sort by composite score\n",
        "ranked_models = sorted(model_scores.items(), key=lambda x: x[1]['composite_score'], reverse=True)\n",
        "\n",
        "# Display ranking\n",
        "print(\"\\nüèÜ MODEL RANKING (Multi-Criteria Composite Score):\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Rank':<6} {'Model':<30} {'Score':<8} {'ROC-AUC':<9} {'Accuracy':<9} {'Overfit':<8}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i, (model_name, scores) in enumerate(ranked_models[:10], 1):\n",
        "    print(f\"{i:<6} {model_name:<30} {scores['composite_score']:.4f}   \"\n",
        "          f\"{scores['roc_auc']:.4f}    {scores['accuracy']:.4f}    \"\n",
        "          f\"{scores['overfitting_gap']:.4f}\")\n",
        "\n",
        "# Select best model\n",
        "best_model_name = ranked_models[0][0]\n",
        "best_scores = ranked_models[0][1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ SELECTED BEST MODEL (Intelligent Multi-Criteria Selection)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"   Model: {best_model_name}\")\n",
        "print(f\"   Composite Score: {best_scores['composite_score']:.4f}\")\n",
        "print(f\"   ROC-AUC: {best_scores['roc_auc']:.4f}\")\n",
        "print(f\"   Accuracy: {best_scores['accuracy']:.4f}\")\n",
        "print(f\"   F1-Score: {best_scores['f1_score']:.4f}\")\n",
        "print(f\"   Train Accuracy: {best_scores['train_accuracy']:.4f}\")\n",
        "print(f\"   Overfitting Gap: {best_scores['overfitting_gap']:.4f}\")\n",
        "print(f\"   Optimized: {'Yes' if best_scores['is_optimized'] else 'No'}\")\n",
        "\n",
        "# Additional validation for optimized models\n",
        "if not best_scores['is_optimized']:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Best model is not optimized!\")\n",
        "    print(\"   Checking if an optimized version exists in top 3...\")\n",
        "\n",
        "    for rank, (model_name, scores) in enumerate(ranked_models[:3], 1):\n",
        "        if scores['is_optimized']:\n",
        "            print(f\"   ‚Üí Found optimized model at rank {rank}: {model_name}\")\n",
        "            print(f\"   ‚Üí Score difference: {best_scores['composite_score'] - scores['composite_score']:.4f}\")\n",
        "\n",
        "            # If score difference is small (<0.01), prefer optimized version\n",
        "            if (best_scores['composite_score'] - scores['composite_score']) < 0.01:\n",
        "                print(f\"   ‚Üí Selecting {model_name} instead (negligible score difference)\")\n",
        "                best_model_name = model_name\n",
        "                best_scores = scores\n",
        "            break\n",
        "\n",
        "# Save the best model\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "# Create filename\n",
        "model_filename = f\"{best_model_name.replace(' ', '_').lower()}_best.pkl\"\n",
        "model_path = f\"models/{model_filename}\"\n",
        "\n",
        "# Save the best model using pickle\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"\\nüíæ Best model saved successfully!\")\n",
        "print(f\"   Model: {best_model_name}\")\n",
        "print(f\"   ROC-AUC: {best_scores['roc_auc']:.4f}\")\n",
        "print(f\"   Path: {model_path}\")\n",
        "\n",
        "# Save the scaler for deployment\n",
        "scaler_path = \"models/scaler.pkl\"\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f\"\\n‚úÖ Scaler saved to: {scaler_path}\")\n",
        "\n",
        "# Save label encoders dictionary\n",
        "encoders_path = \"models/label_encoders.pkl\"\n",
        "with open(encoders_path, 'wb') as f:\n",
        "    pickle.dump(le_dict, f)\n",
        "\n",
        "print(f\"‚úÖ Label encoders saved to: {encoders_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üì¶ MODEL ARTIFACTS SAVED - READY FOR DEPLOYMENT!\")\n",
        "print(\"=\"*80)\n",
        "print(\"Files saved:\")\n",
        "print(f\"   1. {model_path} (Best ML model)\")\n",
        "print(f\"   2. {scaler_path} (Feature scaler)\")\n",
        "print(f\"   3. {encoders_path} (Categorical encoders)\")\n",
        "print(\"\\nYou can now use these files to make predictions on new data!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "7bwpS6YmAkYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}